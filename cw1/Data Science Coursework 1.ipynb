{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "outside-hunter",
   "metadata": {},
   "source": [
    "# Data Science: Coursework 1\n",
    "\n",
    "### Shri Lekkala\n",
    "### CID: 01499487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "integrated-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules used throughout the coursework\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# Set a random seed to fix the results\n",
    "np.random.seed(1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-segment",
   "metadata": {},
   "source": [
    "## Task 1: Regression\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-fusion",
   "metadata": {},
   "source": [
    "### 1.1 Linear Regression\n",
    "***\n",
    "\n",
    "#### Question 1.1.1\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-antibody",
   "metadata": {},
   "source": [
    "First the training and the test data are imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "august-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training and test sets\n",
    "test_data = pd.read_csv('./regression_test.csv', header=None)\n",
    "train_data = pd.read_csv('./regression_train.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-belarus",
   "metadata": {},
   "source": [
    "We can check the structure of the dataset as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pregnant-oklahoma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.413447</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>0.115735</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>0.984960</td>\n",
       "      <td>0.797449</td>\n",
       "      <td>-0.773684</td>\n",
       "      <td>0.985161</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.983048</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>1.176469</td>\n",
       "      <td>-0.487723</td>\n",
       "      <td>-0.773598</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.412788</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.034027</td>\n",
       "      <td>-1.034035</td>\n",
       "      <td>-0.386091</td>\n",
       "      <td>0.819700</td>\n",
       "      <td>0.207144</td>\n",
       "      <td>-0.418203</td>\n",
       "      <td>0.819617</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-0.857929</td>\n",
       "      <td>0.379323</td>\n",
       "      <td>-0.803625</td>\n",
       "      <td>-0.386091</td>\n",
       "      <td>-0.857939</td>\n",
       "      <td>-0.487723</td>\n",
       "      <td>-0.418305</td>\n",
       "      <td>29.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.387983</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.211099</td>\n",
       "      <td>-0.211084</td>\n",
       "      <td>0.261784</td>\n",
       "      <td>-0.510932</td>\n",
       "      <td>-0.923682</td>\n",
       "      <td>-0.671859</td>\n",
       "      <td>-0.511320</td>\n",
       "      <td>-0.102376</td>\n",
       "      <td>0.344213</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>0.131334</td>\n",
       "      <td>0.261784</td>\n",
       "      <td>0.344218</td>\n",
       "      <td>-0.487727</td>\n",
       "      <td>-0.671863</td>\n",
       "      <td>24.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.347952</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.720322</td>\n",
       "      <td>-0.720323</td>\n",
       "      <td>-0.412006</td>\n",
       "      <td>0.846768</td>\n",
       "      <td>0.324494</td>\n",
       "      <td>-0.248591</td>\n",
       "      <td>0.846699</td>\n",
       "      <td>-0.601276</td>\n",
       "      <td>-0.488039</td>\n",
       "      <td>0.369674</td>\n",
       "      <td>-0.381702</td>\n",
       "      <td>-0.412006</td>\n",
       "      <td>-0.488023</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.248524</td>\n",
       "      <td>27.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.330562</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.437258</td>\n",
       "      <td>-0.437249</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.299699</td>\n",
       "      <td>0.918355</td>\n",
       "      <td>0.313581</td>\n",
       "      <td>0.299802</td>\n",
       "      <td>-0.601276</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.342811</td>\n",
       "      <td>0.020597</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>1.176460</td>\n",
       "      <td>-0.487724</td>\n",
       "      <td>0.313542</td>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4         5         6         7   \\\n",
       "0  1.0 -0.413447 -0.487722  0.115738  0.115735  0.158124  0.984960  0.797449   \n",
       "1  1.0 -0.412788 -0.487722 -1.034027 -1.034035 -0.386091  0.819700  0.207144   \n",
       "2  1.0 -0.387983 -0.487722 -0.211099 -0.211084  0.261784 -0.510932 -0.923682   \n",
       "3  1.0 -0.347952 -0.487722 -0.720322 -0.720323 -0.412006  0.846768  0.324494   \n",
       "4  1.0 -0.330562 -0.487722 -0.437258 -0.437249 -0.144217  0.299699  0.918355   \n",
       "\n",
       "         8         9         10        11        12        13        14  \\\n",
       "0 -0.773684  0.985161 -0.803212  1.176466  0.441052 -0.983048  0.158124   \n",
       "1 -0.418203  0.819617 -0.666608 -0.857929  0.379323 -0.803625 -0.386091   \n",
       "2 -0.671859 -0.511320 -0.102376  0.344213  0.441052  0.131334  0.261784   \n",
       "3 -0.248591  0.846699 -0.601276 -0.488039  0.369674 -0.381702 -0.412006   \n",
       "4  0.313581  0.299802 -0.601276  1.176466  0.342811  0.020597 -0.144217   \n",
       "\n",
       "         15        16        17    18  \n",
       "0  1.176469 -0.487723 -0.773598  23.9  \n",
       "1 -0.857939 -0.487723 -0.418305  29.9  \n",
       "2  0.344218 -0.487727 -0.671863  24.5  \n",
       "3 -0.488023 -0.487722 -0.248524  27.5  \n",
       "4  1.176460 -0.487724  0.313542  18.4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-hungarian",
   "metadata": {},
   "source": [
    "Firstly we note that there is already a column of ones for the intercept term in linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-scanning",
   "metadata": {},
   "source": [
    "Usually, we make a decision on whether and how to standardise the data here.\n",
    "However by checking the full data (both training and test together), we see that it is already standardised:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "comparative-letters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -0.  0. -0.  0.  0. -0. -0.  0. -0. -0. -0.  0. -0.  0. -0. -0.  0.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# NB our data is already standardised\n",
    "full_data = pd.concat([test_data, train_data])\n",
    "full_X = np.array(full_data.iloc[:,:-1])\n",
    "print(np.mean(full_X, 0).round(decimals=3))\n",
    "print(np.std(full_X, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-weather",
   "metadata": {},
   "source": [
    "Thus, except in the case where the column is all ones, the mean of each column is 0 and the standard deviation is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-airline",
   "metadata": {},
   "source": [
    "Next we separate the data sets in terms of the X and the Y datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "welcome-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train_data.iloc[:,:-1])\n",
    "Y_train = np.array(train_data.iloc()[:,-1])\n",
    "\n",
    "X_test = np.array(test_data.iloc[:,:-1])\n",
    "Y_test = np.array(test_data.iloc()[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-meditation",
   "metadata": {},
   "source": [
    "As we have explored maximum likelihood estimation in lectures, I will apply the same method for this regression problem.\n",
    "\n",
    "In particular we wish to obtain the parameters  $\\boldsymbol\\beta^{\\mathrm{ML}}$ that maximize the likelihood\n",
    "$$\n",
    "p(\\mathcal Y | \\mathcal X, \\boldsymbol\\beta) = \\prod_{n=1}^N p(y_n | \\boldsymbol x_n, \\boldsymbol\\beta)\\,.\n",
    "$$\n",
    "\n",
    "And once we have that we can can compute the maximum likelihood estimate using the formula:\n",
    "$$\n",
    "\\boldsymbol\\beta^{\\text{ML}} = (\\boldsymbol X^T\\boldsymbol X)^{-1}\\boldsymbol X^T\\boldsymbol y \\, .\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "improving-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the MLE given X and y\n",
    "def max_lik_estimate(X, y):\n",
    "    # X: N x D matrix of training inputs\n",
    "    # y: N x 1 vector of training targets/observations\n",
    "    # returns: maximum likelihood parameters (D x 1)\n",
    "    N, D = X.shape\n",
    "    \n",
    "    beta_ml = np.linalg.solve(X.T @ X, X.T @ y)\n",
    "    return beta_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-concept",
   "metadata": {},
   "source": [
    "Next we have a function that outputs the predicted values given some test data and the beta parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "negative-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_estimate(X_test, beta):\n",
    "    # X_test: K x D matrix of test inputs\n",
    "    # beta: D x 1 vector of parameters\n",
    "    # returns: prediction of f(X_test); K x 1 vector\n",
    "    \n",
    "    prediction = X_test @ beta\n",
    "    \n",
    "    return prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-correction",
   "metadata": {},
   "source": [
    "The parameters of this particular model are obtained below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "distinguished-arkansas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.25206705e+01 -6.23509421e-01  5.07191271e+03 -3.55100636e+04\n",
      "  3.55098886e+04  1.39496495e+09  9.79427526e+02 -1.64223172e-01\n",
      "  1.20208274e+03 -9.76305983e+02 -5.01509709e-02 -6.12934767e+03\n",
      "  7.48646362e-01 -3.71494965e+00 -1.39496496e+09  6.12761154e+03\n",
      " -5.07077881e+03 -1.20558061e+03]\n"
     ]
    }
   ],
   "source": [
    "beta_ml = max_lik_estimate(X_train,Y_train)\n",
    "print(beta_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-server",
   "metadata": {},
   "source": [
    "Next the in-sample MSE is calculated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "british-hawaiian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sample MSE    : 24.38006444485437\n"
     ]
    }
   ],
   "source": [
    "# in sample MSE\n",
    "train_preds = predict_with_estimate(X_train, beta_ml)\n",
    "MSE_train = np.mean((Y_train - train_preds) ** 2)\n",
    "print(\"In sample MSE    : \" + str(MSE_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-inventory",
   "metadata": {},
   "source": [
    "#### Question 1.1.2\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-shelter",
   "metadata": {},
   "source": [
    "We then use the model on the test data and obtain a prediction which is used to compute the out-of-sample MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "continuing-monster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of sample MSE: 19.525828624573784\n"
     ]
    }
   ],
   "source": [
    "# out of sample MSE\n",
    "test_preds = predict_with_estimate(X_test, beta_ml)\n",
    "MSE_test = np.mean((Y_test - test_preds) ** 2)\n",
    "print(\"Out of sample MSE: \" + str(MSE_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-dating",
   "metadata": {},
   "source": [
    "We observe the the out-of-sample MSE seems to be lower than the in-sample MSE.\n",
    "Initially we might think this is strange as the model was trained using in-sample data, but performs better on the out-of-sample data.\n",
    "\n",
    "However this can be explained by the fact that there could be outliers in the training set causing the MSE to be higher. Furthermore, as the training set is assumed to be one random sample from the available data, this could just be a case where the sample is not representative of the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-improvement",
   "metadata": {},
   "source": [
    "### 1.2 Ridge Regression\n",
    "***\n",
    "\n",
    "#### Question 1.2.1\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-pacific",
   "metadata": {},
   "source": [
    "Next we implement a ridge regression model, which is similar to linear regression, however we add a penalty term  $\\lambda$.\n",
    "\n",
    "So in the least squares sense of linear regression, the loss function is:\n",
    "\n",
    "$$\n",
    "\\underset{\\boldsymbol\\beta}{\\text{min}} \\ \\text{L}_{\\text{ridge}} (\\boldsymbol\\beta) = \\underset{\\boldsymbol\\beta}{\\text{min}} \\| \\mathcal Y - \\mathcal X \\boldsymbol\\beta \\|^2 + \\lambda \\| \\boldsymbol\\beta \\|^2 \n",
    "$$\n",
    "\n",
    "and the beta parameters we obtain is given by the formula:\n",
    "\n",
    "$$\n",
    "\\boldsymbol\\beta^{*}_{\\text{ridge}} = (\\boldsymbol X^T\\boldsymbol X + \\lambda I)^{-1}\\boldsymbol X^T\\boldsymbol y \\, .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-apple",
   "metadata": {},
   "source": [
    "First we have a function to compute and return the beta parameters for ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "australian-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_estimate(X, y, penalty):\n",
    "    # X: N x D matrix of training inputs\n",
    "    # y: N x 1 vector of training targets/observations\n",
    "    # returns: maximum likelihood parameters (D x 1)\n",
    "    \n",
    "    N, D = X.shape\n",
    "    I = np.identity(D)\n",
    "    beta_ridge = np.linalg.solve(X.T @ X + penalty * I, X.T @ y)\n",
    "    return beta_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-legislation",
   "metadata": {},
   "source": [
    "As our aim is to perform cross-validation, next we have a function to randomly split a given dataset into the given number of folds as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "theoretical-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_split(data, num_folds):\n",
    "  fold_size = int(len(data) / num_folds)\n",
    "  data_perm = np.random.permutation(data)\n",
    "  folds = []\n",
    "  for k in range(num_folds):\n",
    "    folds.append(data_perm[k*fold_size:(k+1)*fold_size, :])\n",
    "\n",
    "  return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-ecuador",
   "metadata": {},
   "source": [
    "Next we aggregate the X and Y data into one array, so they can be used for cross validation.\n",
    "And we generate the folds which are stored in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "systematic-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.hstack((X_train, Y_train[:, np.newaxis]))\n",
    "\n",
    "# Generate the folds\n",
    "folds = cross_val_split(train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-bidding",
   "metadata": {},
   "source": [
    "In order to scan the optimal $\\lambda$ term, we create a vector of different possible lambdas from 0 to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "reverse-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vec = np.linspace(0, 100, num=1001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-employment",
   "metadata": {},
   "source": [
    "Finally, we create a function that has one loop through the set of folds and another loop over the vector of lambdas, and applies ridge ression to every possible combination of these.\n",
    "\n",
    "The training and validation MSEs are also computed in the function and they are stored in dictionaries which are returned at the end of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "instrumental-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_evaluate_ridge(folds, lambda_vec):\n",
    "    # create dictionaries\n",
    "    train_MSE = {1:[], 2:[], 3:[], 4:[], 5:[]}\n",
    "    val_MSE = {1:[], 2:[], 3:[], 4:[], 5:[]}\n",
    "\n",
    "    for i in range(len(folds)):\n",
    "        print('Fold', i+1)\n",
    "        # define the training set (i.e. selecting all folds and deleting the one used for validation)\n",
    "        train_set = np.delete(np.asarray(folds).reshape(len(folds), folds[0].shape[0], folds[0].shape[1]), i, axis=0)\n",
    "        train_folds = train_set.reshape(len(train_set)*train_set[0].shape[0], train_set[0].shape[1])\n",
    "        X_train = train_folds[:,:-1]\n",
    "        y_train = train_folds[:, -1]\n",
    "        \n",
    "        # define the validation set\n",
    "        val_fold = folds[i]\n",
    "        X_val = val_fold[:,:-1]\n",
    "        y_val = val_fold[:, -1]\n",
    "    \n",
    "        # train the model and obtain the parameters for each lambda\n",
    "        for pen in lambda_vec:\n",
    "            \n",
    "            beta_ridge = ridge_estimate(X_train, y_train, penalty=pen)\n",
    "            \n",
    "            # evaluate\n",
    "            # training data MSE\n",
    "            train_preds_ridge = predict_with_estimate(X_train, beta_ridge)\n",
    "            MSE_train_ridge = np.mean((y_train - train_preds_ridge) ** 2)\n",
    "            \n",
    "            # validation data MSE\n",
    "            test_preds_ridge = predict_with_estimate(X_val, beta_ridge)\n",
    "            MSE_val_ridge = np.mean((y_val - test_preds_ridge) ** 2)\n",
    "            \n",
    "            # store these in the appropriate dictionaries\n",
    "            train_MSE[i+1].append(MSE_train_ridge)\n",
    "            val_MSE[i+1].append(MSE_val_ridge)\n",
    "    \n",
    "    print(\"Training finished.\")\n",
    "    return train_MSE, val_MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-magic",
   "metadata": {},
   "source": [
    "We then call and run the function using our folds and lambda vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "psychological-transition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "train_MSE, val_MSE = cross_val_evaluate_ridge(folds, lambda_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-pastor",
   "metadata": {},
   "source": [
    "Next, we consider a particular fold, in this case fold 1.\n",
    "And we plot the MSE errors obtained against the different penalty terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "tender-amplifier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAAEYCAYAAACeKcVvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABLQUlEQVR4nO3dd3gV1dbA4d9KCAkk1ACh9ypEWiiCYFCuBbFhxQaiYC/XclGvBdu113vVz94loEgRsYFEQBQIvYYaCAQCCYT0vr8/ZoKHkN4m55z1Pk+enOlrz8yZdWbPnhkxxqCUUkqp2s3H6QCUUkopVTpN2EoppZQb0IStlFJKuQFN2EoppZQb0IStlFJKuQFN2EoppZQbqFTCFpFIEbmlqoIpZVm3i0i8iKSKSHBNLNOdiUg9EfleRI6LyDdOx1OVRGSiiCxz6U4Vkc7251PKLSLPikiCiBxyKubaRkTCRWS/03HUhJo+dojI/4nI4yUMNyLStbrjcCci0t7ePr5VPN+O9vpOFZEplZzXpyLybAnDK7RdRcTfji+npPlDGRK2iMSISIY9w3gR+UREgsoZUMFKq1Oe6Vym9wNeA841xgQZYxKLmf+aQv2biUi2iMS49DtTRJbbB/SjIvKHiAyyh00UkTy7rK5/rSsSt8OuAEKAYGPMlU4HU53sfWK33XlSuUWkHfAAcJoxpmVNx+YuB2f7ez66gtNW6vtdnUo7dlRwnq7HxEP2gfzEMdEYc5sx5pnKLqcCcUWKSKYdV4KIfCcirWo6joowxuyzt09eNS2isTHmfTjxYzW/0DH++2paLvYyr7LzTrqIRLoOM8ZkGWOCgK9Km09Zz7Avsmc4ABgEPFbegCspBAgANpcyXqCI9HHpvhbYU9AhIg2B+cB/gaZAG+ApIMtlmj/tHcf1L66yBSj8y7G8B7cKHAw7ANuNMbnlnK4iy6oyVbDswuXuACQaYw5XIBYREb1sVM2qeX8r67HjFKVs/4JjYj+gP/BIhSOsWnfZcXUFgoBXqnoBtfGHWQXEFTrGX1TNyzsKvAG8UJmZlOtgZIw5APwI9Ck8TER8ROQxEdkrIodF5HMRaWQPXmL/T7J/zZxRxPT+IvKGiMTZf2/Y/boD0S7T/1ZCiF8AE1y6bwQ+d+nubpdjujEmzxiTYYz5xRizoUwr4NSYe4rIr/aZerSIXOUy7FMReVdEFohIGjDK/mU+VUQ2AGkiUkdELhaRzSKSZP9C7uUyj6LGnyoiB0QkxV7mOUXE9RTwBHC1vb5vLmn7uJwh3Swi+4Ai17GITBaRnXZ55xXUPIhVBfhKoXHnisj99ufWIjJLRI6IyB4RucdlvGki8q2IfCkiycDEIpYbbC8vWURWAl0KDTci0rWIct8K/Aq0trs/tccfav/aTRKR9SIS7jKvSBF5TkT+ANKBzmXYzm+LyA/2NlkhIl3sYQX7/Xp7+VcXUbaJYtXy/FesWp9trttURBqJyEcictDe7s+K/ePPnnaZiLwiIsfsdXuBy7Q3ichWO67d9vooart+AbQHvrfj/JddnrsLjbdBRC4tYhZFfr9FZJK9/GMi8rOIdCi0ze4UkR3ADrGr6O1lH7bLe6mIjBGR7fa6f9Rl+sEiEmXvE/Ei8loR5Sry2CEiw0Rklb2+V4nIMJdpTtn+Ra2zAsaYQ8DPWIm7YB4nVZ2KyEN2eeJEZFKhGIPFuoSTbMfyrJx8uafYfa+UuJKAOYXiKmk/Li2Ok7aX3W+siKyzv0fLReR0l/GLPE4Vt92kUC2NWMeMeXasO0Vkssu8p4nITLGOYSliHT/DyrJeSiMivex9IMme78UljFvsdi3MGLPQGDMTqNzJnzGmxD8gBhhtf26H9Uv1Gbs7ErjF/jwJ2Im1gwcB3wFf2MM6AgaoU8Jyngb+AloAzYHlLsspcXqX4R2BWMAX6IX1ZR0NxNjjNQQSgc+AC4AmheYzEVhW2jqxxw20l3UTUAer9iEB6G0P/xQ4DgzH+mEUYK/LdfZ6rIf1AyIN+AfgB/zLXod1Xda96/g97GW2dil3l2LimwZ86dJdlu3zuV2uekXM72y7fAMAf6xaiiX2sJF2XGJ3NwEygNZ22VdjJdK69vJ3A+e5xJkDXGqPW9SyI4CZdmx9gAOu28mOvWsx5Q4H9rt0t7H3gTH28v5hdzd32af3Ab3t7dqoDNv5KDDYHv4VEFFUbMVsp4lALvBPex+4Gmu/aWoPnwO8Z5e9BbASuNVl2hxgMtY+fzvWAaFgO1yI9eNGgLOwEtCAYtZLDPb33O6+Cljh0t3XXk91S/j+1XHpdynW/tbLXi+PAcsLrZdfsWq66tnx5GLtJ352mY4AXwMN7O2RCXS2p/8TuMH+HAQMLeXYUMfubgocA26w4xpvdwcXs/39SjkmtgU2Am+6DP8UeNb+fD4Qj7XfBtrlcd1fI+y/+sBpWPvasrIcY4qIK5K/j8fBwEJgbhmPV8XGUcz2GgAcBoZg7XsT7PXiTwnHqeK2WxHb6XfgHazjZj97XzjH5TueifUd9gWeB/4qy/Yvat936e+Htc8+inWsOhtIAXqUd7uW8H2/BYgsZtiJ+Rc7fUkDXXbOVCAJ2GuvxHpF7CCLgDtcpuuBdTCpU9RKK2I5u4AxLt3n8XeiLXF61+FYO+l5WFUP/8YlYdvj9rJXzH6sA8Q8IKTQwTPJ5W9XMcu8GlhaqN97wJMuK//zItblJJfux4GZLt0+WMkovJjxu2J9SUZTxIGk0LKmcXLiKsv26VzC/D4CXnLpDrKn74iVEPYBI+1hk4Hf7M9DgH2F5vUI8IlLnEtKWK6vvZyeLv3+Q8UT9lTsHyou/X4GJrjs00+Xczt/6DJsDLCtqNiKKd9EXJKs3W8lVkIJwbpcU89l2Hhgscu0O12G1beX17KYZc0B7i1mvcRwcsL2x/oh0s3ufgV4p7Tvn0u/H4GbC+3b6UAHl/VydqHtlAH42t0N7HGGuIyzGrjU/rwE63JWs1K+ByfFZq/XlYXG+ROYWNT2L2aeMVjHxBR73ouwrpGecuAFPgZecBnWvWCf4O99u4fL8Gf5O2GXuO8VEVekvY6P28tYB7QvbV6lxVHM9noX+4TKpV801g/DYo9TxW03Tj6GtwPygAYuw58HPnX5ji90GXYakFGOfTMcyOfk4/xVwAjgEODjMu50YFp5tmsp+06lEnZZq8QvNcY0NsZ0MMbcYYzJKGKc1lgJvcBee+WHlHEZRU1fkcZen2MdyMYDXxYeaIzZaoyZaIxpi/XrqDXWtYUCf9llLfjrUngetg7AELvqJElEkoDrANeGTbFFTOfa76QyG2Py7eFtihrfGLMTuA9rhz0sIhFS9gZxZdk+RcVbXKypWGdcbYy1t0VgrXOw2g4UNKDogFUl7bqeHi3HcpvbcbqOs7eYccuiA3BloXjOBFwb58QWGr+07eza+jwd68dMeRyw12GBgn2/A9av/oMuy34P60z7lGUbY9Ltj0EAInKBiPxlVysmYf2YaFaWgIwxWVi1GteLdR13PNYlp7LqALzpEvdRrB92Re7btkTzd6OjgmNMvMvwDP5etzdjHSS32VW4Y8sYV+HvAXZ3SXEV5VJjTAOsg39Pil+vrSl+3y1q3y7vvlfYPcaYRsDpWDVdbcswr9LiKC62BwrNrx3WWXVJx6mybLfWwFFjTIpLv8LbqPB3LkDKd209rtBxfqa93Fj7OFzccl1jrKpjUplVZYOaOKyNWKA91tlqPNYvj4pMX5H6/llYVYG7jTElrkRjzDasXzWnXJMvg1jg90IbPcgYc7vrIoparMvnk8osIoK10x8obh7GmK+NMWfa0xngxTLGW9L2KSne4mINxKp2K4h1OnCFWNcph2BtB7DW055C66mBMWZMGZd7xI6zXaHYKyoW6wzbNZ5AY4xrYxBTaPzStnNltbG3fYGCfT8W6wy7mcuyGxpjepc2QxHxx9oGr2DVIDUGFmAlzaIUtQ0+wzqonwOkG2P+LMe0sVhV967rrZ4xZnkp05WJMWaHMWY81o+XF4Fv7X2yNIW/B2Ct72K/c6XE8TvWMaS4xl0HKX7fLdi327r0cx23wvueMWYj1lny2/a+VdK8SovjxGwLxfZcofnVN8ZMt5df5HGqjNstDmgqIg1c+hXeRtUhDmgnJzc0LG65JW3XalOVCXs68E8R6STWLQ7/AWYYq7XuEawqiJIacEwHHhOR5iLSDOta1ilnyKUxxqRhXXs45f5wu9HFAyLS1u5uh3Xm8Fd5l4PV2ry7iNwgIn723yBxaTRWBjOBC0XkHLFuP3kA6wC9vKiRRaSHiJxtH4wzsc44ynobREnbpyy+Bm4SkX728v+DdY0zBsAYsxZrO38I/GysRi9gVe8m241Q6omIr4j0EftWutLYZ1zfAdNEpL6InMbJDQvL60vgIhE5z44lQKwGT22LGb+y2zmeUhouYR287rHnfSXWZZsFxpiDwC/AqyLSUKyGg11E5KwyLLcuVrX2ESBXrMZo55YnTjtB5wOvUvLZdVHf7/8DHhGR3nCi8VyV3V4oIteLSHP7bCjJ7l2W78ICrO15rViNOK/GqlKdX4lw3gD+ISL9ihg2E5goIqeJSH2sKmigyH27J1ZD2QKV3fc+w9q3Li5pXmWIoygfALeJyBCxBIrIhSLSoKTjVFm2mzEmFusY+Lz9/Twd68y81NueKmkFVpuif9nrJxy4CKv2sLBit2tRCo41WDUZPna5/MobYFUm7I+xvtRLsG6lygTuhhNVdc8Bf9jVJ0OLmP5ZIArYgNWIY43dr9yMMVHGmF1FDErBOvtbIVbL7b+ATViJssAZcup92KckF7u65lzgGqxfZoewfjH6lyPOaOB6rAZcCVg7x0XGmOxiJvHHujafYC+vBVb1clkUu33KGOsirGvus7B+XXbBKrur6VjXrb52mS4Pq1z97OUmYCX1RmVdNnAXVlXoIayzmU/KMe1J7IPBJVjr7QjWmcJDFPNdqILtPA34zN7vi2vhuwLohrVungOuMH/fL3wjVvLdgtU46ltOrr4vkh33PVgHlmNYlynmlTDJ81g/mJNE5EGX/p8DoZTw47mo77cxZjbWeooQq/X/JqyGnlXlfGCziKQCbwLXGGMyS5vIXq9jsb7ziVgNPccaYxIqGogx5gjWejrlYSnGmB+xEvpvWA2aCt+BcRfWd+EQ1vdzOvZtppXd9+zjyFvA42WYV7FxFDPvKKy2Kv/D2r928vcdHiUdp8q63cZjXX+OA2ZjXbf/tSzlrih7fV2MtZ8mYLXXutGuiS08bmnbtbAbsH64vIt1rTwD60dPuRS0JlVKOUBEJmI13DzT6ViKIiI3AlNqa3yeRkRexGo0WJlaJI+Jo7LEukQXjXWC8pAxptxJsrrZNRHxWO1VXjLGPFXcuJ5wA7xSqhrYVX13YJ1pqGpgVz/XxapVHIRV9Vsjj3uujXFUNbsdU4DTcZTEbuDZuCzj6lOclFKnEJHzsC4ZxONyiUNVuQZY14/TsC5fvArM9eI4VAm0SlwppZRyA3qGrZRSSrkBvYZdCc2aNTMdO3as0LRpaWkEBpbltlHPoWX2Dlpm71CZMq9evTrBGNO8ikPyeJqwK6Fjx45ERUVVaNrIyEjCw8OrNqBaTsvsHbTM3qEyZRaRGnkymKfRKnGllFLKDWjCVkoppdyAJmyllFLKDeg17CqWk5PD/v37ycws+SmJjRo1YuvWrTUUVe3grmUOCAigbdu2+PmV+9G/SilVZTRhV7H9+/fToEEDOnbsiEhxL0aClJQUGjRoUOxwT+SOZTbGkJiYyP79++nUqZPT4SilvJhWiVexzMxMgoODS0zWyn2ICMHBwaXWmCilVHXThF0NNFl7Ft2eSqnaQBO2UkqpMsvKzePZ+VtIysx3OhSvownbwyQmJtKvXz/69etHy5YtadOmzYnu7OziXrNtiYqK4p577il1GcOGDauSWCMjI2nUqNGJ+Pr168fChQurZN5KqaqXmJrF9R+u4MNle9iQkOd0OF5HG515mODgYNatWwfAtGnTCAoK4sEHHzwxPDc3lzp1it7sYWFhhIWFlbqM5cuXV0msACNGjGD+/PnFDjfGYIzBx8enyO7i5OXl4evrW2VxKuXttsencPNnqzicnMX/ru1P0NHtTofkdfQM2wtMnDiR+++/n1GjRjF16lRWrlzJsGHD6N+/P8OGDSM6OhqwznjHjh0LWMl+0qRJhIeH07lzZ956660T8wsKCjoxfnh4OFdccQU9e/bkuuuuo+DtbwsWLKBnz56ceeaZ3HPPPSfmWxYxMTH06tWLO+64gwEDBrB06dKTumNjY3nooYfo06cPoaGhzJgx40Q8o0aN4tprryU0NJS0tDQuvPBC+vbtS58+fU6Mp5Qqn8jow1z+znIysvOZcesZjD29tdMheSU9w65GT32/mS1xyUUOq+gZ4GmtG/LkRb3LPd327dtZuHAhvr6+JCcns2TJEurUqcPChQt59NFHmTVr1inTbNu2jcWLF5OSkkKPHj24/fbbT7kXee3atWzevJnWrVszfPhw/vjjD8LCwrj11ltZsmQJnTp1Yvz48cXGtXTpUvr163eie9asWfj6+hIdHc0nn3zCO++8Q0xMzEnds2bNYt26daxfv56EhAQGDRrEyJEjAVi5ciWbNm2iU6dOzJo1i9atW/PDDz8AcPz48XKvN6W83WfLY3jq+830aNmQjyaE0bpxPadD8lpembBFJAZIAfKAXGNMmIhMAyYDR+zRHjXGLHAmwqp35ZVXnviBcPz4cSZMmMCOHTsQEXJycoqc5sILL8Tf3x9/f39atGhBfHw8bdu2PWmcwYMHn+jXr18/YmJiCAoKonPnzifuWx4/fjzvv/9+kcsoqko8JiaGDh06MHTo0BP9XLuXLVvG+PHj8fX1JSQkhLPOOotVq1bRsGFDBg8efGK5oaGhPPjgg0ydOpWxY8cyYsSI8q42pbxWTl4+T3+/hS/+2svoXiG8eU0/Av29MmXUGt689kcZYxIK9XvdGPNKVS2gpDPhmn6IiOtr8B5//HFGjRrF7NmziYmJKfaNO/7+/ic++/r6kpubW6ZxCqrFqyrewt0lzd91vO7du7N69WoWLFjAI488wrnnnssTTzxR6diU8nTHM3K46+s1LN2RwK0jO/Ov83vi66O3NzpNr2F7oePHj9OmTRsAPv300yqff8+ePdm9ezcxMTEAVX7teOTIkcyYMYO8vDyOHDnCkiVLGDx48CnjxcXFUb9+fa6//noefPBB1qxZU6VxKOWJ9iamMe6dP/hrdyIvXX46j4zppcm6lvDWM2wD/CIiBnjPGFNQX3uXiNwIRAEPGGOOFZ5QRKYAUwBCQkKIjIw8aXijRo1ISUkpNYC8vLwyjVcZWVlZ+Pn5kZOTQ0ZGxonl3Xnnndx22228/PLLjBw5EmMMKSkppKenk5ubS0pKyolpC6bJz88nNTX1RHfh8QGys7PJzMwkNzeXV199lXPPPZfg4GAGDhxITk7OKWVOT09n6dKlnH766Sf6PfTQQ/Tv35/8/PwT46ampp7UPXr0aH7//XdCQ0MREZ566ikCAwNPiWfFihU8/vjj+Pj4UKdOHV5//fUKr/PMzMxTtnVZpKamVmg6d6Zldl/RR/P479pMDPDAwABapO0iMnJXkeN6SpndiVRF9aW7EZHWxpg4EWkB/ArcDUQDCVjJ/BmglTFmUknzCQsLM1FRUSf127p1K7169So1Bnd8rnZ5pKamEhQUhDGGO++8k27dunHLLbe4bZnLul0LK2hJ7020zO5pZlQs/569kfZN6/PRhEF0bBZY4viVKbOIrDbGlH4PqTqJV1aJG2Pi7P+HgdnAYGNMvDEmzxiTD3wAnFrHqsrsgw8+oF+/fvTu3Zvjx49z6623Oh2SUqoIefmG5xds5V/fbmBo52C+u2N4qclaOcPrqsRFJBDwMcak2J/PBZ4WkVbGmIP2aJcBmxwL0gP885//5J///OdJ/ar7EoBSqnzSsnK5b8Y6ft0Sz/VD2/PkRb3x8/XK8zi34HUJGwgBZtsvdKgDfG2M+UlEvhCRflhV4jGAnhIqpTxWXFIGN38WRfShZKZddBoThpX8SmDlPK9L2MaY3UDfIvrf4EA4SilV49bFJjH58ygysvP4eOIgwnu0cDokVQZel7CVUsqbfb8+jge/WU/zBv58dcsQuoe4Z0NQb6QJWymlvEB+vuGNhdt567edhHVowns3DCQ4yL/0CVWtoa0LPEx4eDg///zzSf3eeOMN7rjjjhKnKbg9bcyYMSQlJZ0yzrRp03jllZIfAjdnzhy2bNlyovuJJ56oktdl6ms4laqctKxcbv9qNW/9tpOrwtry1eQhmqzdkJ5he5jx48cTERHBeeedd6JfREQEL7/8cpmmX7Cg4o9PnzNnDmPHjuW0004D4Omnn67wvArT13AqVTH7j6Vzy2dRbI9P4fGxpzFpuDYuc1d6hu1hrrjiCubPn09WVhZgvUgjLi6OM888k9tvv52wsDB69+7Nk08+WeT0HTt2JCHBesT6c889R48ePRg9evSJV3CCdY/1oEGD6Nu3L5dffjnp6eksX76cefPm8dBDD9GvXz927drFxIkT+fbbbwFYtGgRZ555JqGhoUyaNOlEfB07duTJJ59kwIABhIaGsm3btjKXVV/DqVTJomKOcsn//uDAsQw+njiIm8/spMnajekZdnX68WE4tLHIQfXycsG3Aqu/ZShc8EKxg4ODgxk8eDA//fQTl1xyCREREVx99dWICM899xxNmzYlLy+Pc845hw0bNpz0WFBXq1evJiIigrVr15Kbm8uAAQMYOHAgAOPGjWPy5MkAPPbYY3z00UfcfffdXHzxxYwdO5YrrrjipHllZmYyceJE5s6dy4ABA7jxxht59913ue+++wBo1qwZa9as4Z133uGVV17hww8/PCUefQ2nUuUzc1Us/56zkTaN6/HhhEF0bRHkdEiqkvQM2wMVVIuDVR1e8D7qmTNnMmDAAPr378/mzZtPut5c2NKlS7nsssuoX78+DRs25OKLLz4xbNOmTYwYMYLQ0FC++uorNm/eXGI80dHRdOrUiW7dugEwYcIElixZcmL4uHHjABg4cOCJF4YUNmLECNatW3fir0uXLgAVeg0ncMprOBcuXMjUqVNZunQpjRo1KrE8StVmefmGZ+dv4V+zNjCkUzBz7hyuydpD6Bl2dSrhTDijGp8lfumll3L//fezZs0aMjIyGDBgAHv27OGVV15h1apVNGnShIkTJ5KZmVnifIqrOps4cSJz5syhb9++fPrpp6W+AKC059UXvKKzuFd4lkRfw6nU35Izc7j767X8vv0IE4d15LELe1FHn1zmMXRLeqCgoCDCw8OZNGnSibPr5ORkAgMDadSoEfHx8fz4448lzmPkyJHMnj37xFu+vv/++xPDUlJSaNWqFTk5OXz11Vcn+jdo0KDIx4/27NmTmJgYdu2y3vrzxRdfcNZZZ1VFUUstg76GU3mLPQlpXPb2H/yxM4H/XBbKtIt7a7L2MHqG7aHGjx/PuHHjTlSN9+3bl/79+9O7d286d+7M8OHDS5x+wIABXH311fTr148OHTowYsSIE8OeeeYZhgwZQocOHQgNDT2RpK+55homT57MW2+9daKxGUBAQACffPIJEyZMID8/n0GDBnHbbbeVqzyFr2E/9thjhIWV/LKfyy67jD///JO+ffsiIrz00ku0bNnylIZtGzdu5KGHHsLHxwc/Pz/efffdcsWmlNOW7Ujgzq/X4CPw5S1DGNo52OmQVDXwytdrVhV9vWb5uHOZ9fWaZadlrjnGGD7/cy9Pz99C1+ZBfDghjHZN69fIsvX1mjVPz7CVUsoNZefm8+S8zUxfuY/RvVrwxjX9CfLXQ7on062rlFJu5mhaNrd/uZoVe45ye3gXHjy3B74+en+1p9OEXQ2MMfpwAg+il41UbRJ9KIVbPl9FfHIWr1/dl8v6t3U6JFVDtAlhFQsICCAxMVEP8h7CGENiYiIBAQFOh6IUv26JZ9w7f5CZk8+MKUM1WXsZPcOuYm3btmX//v0cOXKkxPEyMzO9Lgm4a5kDAgJo21YPjMo5+fmG/y3eyWu/bie0TSPev3EgrRrVczosVcM0YVcxPz+/E0/QKklkZCT9+/evgYhqD28ss1KVlZaVy4PfrOfHTYe4rH8bnh8XSoCfvrDGG2nCVkqpWmpfYjpTvrDetPXvMb24ZYS+vMObacJWSqlaaNmOBO6avgZj4NObBjOye3OnQ1IO88qELSIxQAqQB+QaY8JEpCkwA+gIxABXGWOOORWjUso7GWP4aNke/rNgK11bBPHBjWF0CA4sfULl8by5lfgoY0w/l6ftPAwsMsZ0AxbZ3UopVWMyc/J44Jv1PPvDVkb3CuG7O4ZrslYneOUZdjEuAcLtz58BkcBUp4JRSnmXg8czuO2L1azff5z7RnfjnrO74VNbH4aSm+10BF7JK58lLiJ7gGOAAd4zxrwvIknGmMYu4xwzxjQpYtopwBSAkJCQgQUv1yiv1NRUgoK86x21WmbvoGUuvx3H8vjv2iyy8wyTT/dnYEjtPZeqn7aP0I3PsaHdBDLaDKvQPEaNGqXPEq+A2rtXVK/hxpg4EWkB/Coi20qdwmaMeR94H6yXf1T04ff6ggTvoGX2DpUp8/SV+3jp1020aVyP928Mo3tILX5Bzs5F8M2/wa8+dRo097rt7DSvTNjGmDj7/2ERmQ0MBuJFpJUx5qCItAIOOxqkUsqjZefm88z8LXzx115GdGvG/8YPoFF9P6fDKt6qj2DBQ9CiF1w7g5S1O52OyOt4XaMzEQkUkQYFn4FzgU3APGCCPdoEYK4zESqlPF1CahbXf7SCL/7ay60jO/PpTYNrb7LOz4OfHoUf7oeu58Ckn6CRPvnPCd54hh0CzLYfPlAH+NoY85OIrAJmisjNwD7gSgdjVEp5qE0HjjPl8ygS07J54+p+XNq/jdMhFS8rFb6bDNELYPCtcN5/wNcb00bt4HVr3hizG+hbRP9E4Jyaj0gp5S3mrjvA1FkbaFq/Lt/eNozQto2cDql4yXHw9dUQvwkueBmGTHE6Iq/ndQlbKaVqWk5ePi/8uI2Plu1hcMemvHP9AJoF+TsdVvEOrreSdVYKjJ8B3c91OiKFJmyllKpWCalZ3PnVGlbsOcrEYR3594W98POtxc2Hon+Eb2+Gek1g0s/Qso/TESmbJmyllKom62KTuP3L1RxNy+a1q/oybkAtbqxlDPz1Lvz8KLTqC9fOgAYtnY5KudCErZRS1WDGqn08PmczLRr6M+v2YfRpU4uvV+flwo//gqiPoOdYGPc+1NVHotY2mrCVUqoKZeXmMW3eFqav3MeIbs1465r+NAms63RYxctMhm8mwq5FMPxeOGca+NTiKnsvpglbKaWqyKHjmdz+1WrW7kvi9vAuPHhuD3xr6/PAAY7FwNfXQOIOuOhNGDjR6YhUCTRhK6VUFVixO5E7v15DRnYe7143gAtCWzkdUsn2/gkzroP8XLh+FnQOdzoiVQpN2EopVQnGGH6NyWHGLyto37Q+0ycPpVttfh44wLqvYd490Lg9XDsTmnV1OiJVBpqwlVKqgjKy83h09kZmb8tmdK8QXru6Lw0DaukjRgHy82HRU/DHG9BpJFz1uXX7lnILmrCVUqoCYo+mc+sXq9l6KJlx3fx45YaBtff91WA/ZnQKRP8AA2+CMS+Dby3+caFOoQlbKaXKacn2I9w9fS3GGD6eMAg5tKV2J+ukWJg+Hg5vhgtegsFTQGpxvKpImrCVUqqM8vMN7/6+i1d+iaZHSAPeu2EgHYIDiTy0xenQihe7CiKuhdxMuPYb6Dba6YhUBWnCVkqpMjiensP9M9exaNthLu7bmhcuD6V+3Vp+CN34Lcy5Axq2ggnfQ4ueTkekKqGW721KKeW8TQeOc/tXqzl0PJOnLu7NjWd0QGpzlXJ+PkQ+D0tegg7D4aovIDDY6ahUJWnCVkqpEsxcFctjczfRtH5dIqacwcAOtbxVdXY6zLkdtsyBftfD2NehTi1+0poqM03YSilVhMycPJ6Yu4mZUfs5s2sz3rymH8G1+ZWYYL3Devp46/WY5z4LZ9yljcs8iCZspZQqZF9iOrd9uZotB5O5++yu3De6e+1+xChA3ForWWelwPgI6HG+0xGpKqYJWymlXCzcEs/9M9cB8PHEMM7uGeJsQGWxeQ7Mvg0Cm8PNv0BIb6cjUtVAE7ZSSgF5+YbXfo3m7cW76NOmIe9eN5B2Tes7HVbJjIElL8Pi56DtYLjmawhq7nRUqpp4bcIWEV8gCjhgjBkrItOAycARe5RHjTELnIpPKVVzElKzuGf6WpbvSmT84HY8eVFvAvx8nQ6rZNlp1i1bW+bA6ddYb9vyC3A6KlWNvDZhA/cCW4GGLv1eN8a84lA8SikHrN57lDu/Wsux9GxeuuJ0rgpr53RIpUvaZz0MJX6zNi7zIl6ZsEWkLXAh8Bxwv8PhKKUcYIzh0+UxPPfDVlo3rsd3dwyjd+tGTodVur3LYcYNkJejTy7zMmKMcTqGGici3wLPAw2AB12qxCcCyVhV5Q8YY44VMe0UYApASEjIwIiIiArFkJqaSlBQUIWmdVdaZu/gDmXOyDV8simLlYfy6N/Cl1tC/Qn0q/gZak2VuVXcL3Tb8R6ZAS3YGPpvMuq3rfZlFqcyZR41atRqY0xYFYfk+YwxXvUHjAXesT+HA/PtzyGAL+CDdeb9cWnzGjhwoKmoxYsXV3had6Vl9g61vcybDxw34S8vNp0enm/eXrzD5OXlV3qe1V7m3GxjfnjQmCcbGvPFOGPSj1Xv8sqgMmUGokwtyAfu9ueNVeLDgYtFZAwQADQUkS+NMdcXjCAiHwDznQpQKVX1jDFMXxnLtO8306S+H9MnD2VIZzd4XGf6UfhmAuxZAsPuhtFPgU8tbxCnqoXXJWxjzCPAIwAiEo5VJX69iLQyxhy0R7sM2ORMhEqpqpaWlcujszcyd10cI7o14/Wr+9Gstj+1DCB+C0SMh+SDcOn/Qb/xTkekHOR1CbsEL4lIP8AAMcCtjkajlKoS2w4lc8dXa4hJSOPBc7tzR3jX2v3u6gLbFsB3k6FuENy0ANrqJV9v59UJ2xgTCUTan29wNBilVJUyxjAzKpYn5m6mYT0/vrplKGd0cYMqcGNg6Svw23PQuj9c8xU0bO10VKoW8OqErZTyTGlZuTw+ZxPfrT3A8K7BvHF1f5o3cIMq8Ox0mHsnbP4OQq+Ci98Cv3pOR6VqCU3YSimPEn0ohTu+Ws3uhDT+Obo7d53dtfa/uAPg+H7rYSgHN1gNy4bfqw9DUSfRhK2U8hjfRMXy+NxNBPn78dXNQxjWtZnTIZXNvr9gxvWQmwXXzoTu5zodkaqFNGErpdxeenYuj8/ZzKw1+zmjczBvju9HiwZu8FxtYyDqI/hxKjTuABOnQ/MeTkelailN2Eopt7Y9PoU7v1rDziOp3HNON+49p5t7VIHnZsEPD8DaL6DbeTDufajX2OmoVC2mCVsp5ZaMMUSsiuWp7zcT5F+HzycNZkQ3N3m1ZHKc9TzwA1Ew8l8Q/gj4+DgdlarlNGErpdzO8YwcHv1uIz9sPMiIbs149aq+7lEFDrD3T5h5I+Skw9VfQq+LnI5IuQlN2Eopt7Jm3zHumb6WQ8czmXp+T24d2dk9HoRiDKz6EH562LpePeF7aNHT6aiUG9GErZRyC/n5hveW7OaVX6Jp1SiAmbedwYD2TZwOq2xyMmHBA7D2S71erSpME7ZSqtY7nJLJAzPXs3RHAheGtuI/40JpVM/P6bDKJjnOumXrwGq9Xq0qRRO2UqpW+337ER6YuY7UrFyeHxfKNYPaIe7yQBG9Xq2qkCZspVStlJ2bz6u/RPPekt30CGnA9MlD6RbSwOmwykavV6tqoAlbKVXr7EtM5+6ItayPTeK6Ie15fOxpBPi5yTug9Xq1qiaasJVStcq89XH8+7uNiMC71w3ggtBWTodUdnq9WlUjTdhKqVohNSuXJ+dajxcd2KEJb17Tj7ZN6jsdVtntWQLfToKcDL1eraqFJmyllONW7z3GP2esY/+xdO45uyt3n9MNP183OTM1hnb7voPfv4DgrjDxB30euKoWmrCVUo7Jzcvn7cW7eOu3Hda91beeQVjHpk6HVXaZyTD3Drrs/h5OuwQueRv83aRhnHI7mrCVUo6IPZrOfTPWsXrvMS7r34anLulNwwA3ubca4PBW63ngR3ezs8skul75mr6/WlUrTdhKqRpljGH22gM8MXczArx5TT8u6dfG6bDKZ9MsmHs31A2ECfPYH5NLV03Wqpp5bcIWEV8gCjhgjBkrIk2BGUBHIAa4yhhzzLkIlfI8xzNyeGzOJr5fH8fgjk157eq+7tWwLC8Hfn0C/noH2g2BKz+Dhq0gJtLpyJQXcJNWHdXiXmCrS/fDwCJjTDdgkd2tlKoiK3YnMubNpSzYeJAHz+3O9ClD3StZpxyCzy6ykvWQ22DCfCtZK1VDvPIMW0TaAhcCzwH3270vAcLtz58BkcDUmo5NKU+Tk5fPGwu3807kLjo0rc+s24fRr11jp8Mqn73L4ZuJkJUCl38EoVc4HZHyQmKMcTqGchOR640xX9qfhxtj/nAZdpcx5n+lTP8t8DzQAHjQrhJPMsY0dhnnmDHmlFcBicgUYApASEjIwIiIiAqVITU1laCgoApN6660zN7BtcwHU/N5f0MWe5LzGdm2Dtf2rEtAHTe61msMbffPo8uuT8mo15LNvR8mLajDKaN5+3Yur1GjRq02xoRVcUiezxjjdn/AmqI+F9VdxLRjgXfsz+HAfPtzUqHxjpUWx8CBA01FLV68uMLTuists3dYvHixycvLN58s2216PLbA9H3qZ7NgQ5zTYZVfZooxMycY82RDY6Zfa0xGUrGjeut2riggytSCXOJuf+5aJS7FfC6qu7DhwMUiMgYIABqKyJdAvIi0MsYcFJFWwOGqC1cp75GYkc+NH69k2c4Ewns058XLTyekYYDTYZXPkWjrLVsJ22H0NBh+n96ypRznrgnbFPO5qO6TBxrzCPAIgIiEY1WJXy8iLwMTgBfs/3OrKlilvIExhjnrDvDYHxmITzb/uSyU8YPd6FWYBdbPgPn3gV99uGE2dA53OiKlAPdN2D1FZAPW2XQX+zN2d+cKzvMFYKaI3AzsA66sfJhKeYejadn8e/ZGftx0iG6Nffhw8gg6BAc6HVb55GTCT1Nh9afQfhhc8bG2Ale1irsm7F5VMRNjTCRWa3CMMYnAOVUxX6W8yaKt8UydtZHkjBwevqAn3fP3uV+yTtwF30yAQxut6u+zHwdfdz08Kk/llnukMWava7eIBAMjgX3GmNXORKWUd0nNyuXZ+VuIWBVLz5YN+OLmwfRq1ZDIyFinQyufLXNh7l0gPjB+BvQ43+mIlCqSWyZsEZkPPGyM2WQ3EFuD9dSyLiLyvjHmDUcDVMrDrdidyAPfrCcuKYM7wrtw7+hu+NfxdTqs8snNtp5atuJdaDMQrvwUGrd3OiqliuWWCRvoZIzZZH++CfjVGHOjiDQA/gDecCwypTxYZk4er/4SzYfL9tC+aX33e7tWgaRY60EoB6Ksp5b94xmoU9fpqJQqkbsm7ByXz+cAHwAYY1JEJN+ZkJTybKv3HuOhb9ez+0ga1w5pz7/H9CLQ3w0PIdt/htm3Ql6u9Szw3pc6HZFSZeKG3zYAYkXkbmA/MAD4CUBE6gFu9H4+pWo/17Pq1o3q8eXNQzizWzOnwyq/vFxY/Cwsex1CQuGqzyC4i9NRKVVm7pqwbwaeBkYDVxtjkuz+Q4FPnApKKU8TFXOUf327gd0JaVw3pD2PjOlFkDueVScfhFk3w94/YMAEuOBF8KvndFRKlYsbfvPAGHMYuK2I/ouBxTUfkVKeJSM7j1d+iebjP6yz6q9uGcLwrm54Vg2wcyHMvg2y0+Cy96DvNU5HpFSFuGXCFpF5JQ03xlxcU7Eo5WlW2WfVexLSuH5oex6+wE3PqvNy4Ldn4I83ocVp1uswW/R0OiqlKswNv4UAnAHEAtOBFZT+/HClVCkysvN4+edoPlm+hzaN6/H1LUMY5q5n1cf2WlXg+1fBwIlw/gtaBa7cnrsm7JbAP4DxwLXAD8B0Y8xmR6NSyk2tijnKQ9+sJyYxnRuGduDhC3q6ZwtwsB+Ecjdg4IpPoM84pyNSqkq45TfSGJOH1TL8JxHxx0rckSLytDHmv85Gp5T7SMnM4aWfovnir720a1qPrycPYVgXNz2rzsmEnx+FqI+g9QDrWeBNOzkdlVJVxi0TNoCdqC/EStYdgbeA75yMSSl3smhrPI/N2cSh5ExuGt6RB8/t4b5n1Ue2w7c3QfwmGHY3nP2EPghFeRy3/HaKyGdAH+BH4CmXp54ppUpxJCWLp77fzPwNB+kR0oB3rhtA//ZNnA6rYoyBdV/Dggeta9TXfgPdz3U6KqWqhVsmbOAGIA3oDtzj8r5dAYwxpqFTgSlVWxlj+Hb1fp79YSsZ2Xk88I/u3HpWF+rW8XE6tIrJSoEfHoANM6DjCBj3PjRs7XRUSlUbt0zYxhg3PcIo5Yy9iWk8Onsjf+xMZFDHJjw/7nS6tghyOqyKO7gevrkJju2B8Edh5IPg42YvH1GqnNwyYSulyiY3L5+P/9jDa79up46PD89e2odrB7fHx8dN74TMz4e/3oFFT0H9YJjwPXQ80+molKoRmrCV8lCb447z8KyNbDxwnNG9Qnjm0t60auTG9yKnHII5t8Ou36DHGLj4fxAY7HRUStUYTdhKeZjUrFxe+2U7ny7fQ9NAf965bgAX9GmJS1sP9xP9I8y9E7LT4cLXIGwSuHN5lKoATdhKeQhjDD9tOsRT328hPiWTawe351/n9aRRfTd+gV12OvzymHVvdctQuPwjaN7D6aiUcoTXJWwRCQCWAP5Y5f/WGPOkiEwDJgNH7FEfNcYscCZKpcpnX2I6T8zbRGT0EU5r1ZB3r3fjW7UKHNoI394MCdFwxl1wzhNQx9/pqJRyjNclbCALONsYkyoifsAyEfnRHva6MeYVB2NTqlyycvP4YMlu/vvbTur4CI+PPY0JZ3Sgjq8b30iRnw8r3oWF06BeU7hhNnQ52+molHKc1yVsY4wBUu1OP/vPOBeRUhXz565EHpuzkV1H0hgT2pLHx57m3o3KAFLi7YZli7RhmVKFiJW/vIuI+AKrga7A28aYqXaV+EQgGYgCHjDGHCti2inAFICQkJCBERERFYohNTWVoCA3vg+2ArTMVSM5yzAjOps/4nJpXk+4/rS69G1ee357V7TMwQmr6BH9X3zzMtjVZRJxrc93m4Zlum+Xz6hRo1YbY8KqOCSP55UJu4CINAZmA3djXbtOwDrbfgZoZYyZVNL0YWFhJioqqkLLjoyMJDw8vELTuistc+Xk5uXz9cp9vPrLdtKzc5kysjN3jepGvbq164Eh5S5zdhr88rjVsCwkFK5wv4Zlum+Xj4howq6A2vOz3AHGmCQRiQTOd712LSIfAPMdC0ypQlbuOcoTczex7VAKw7oE8/QlvenaooHTYVVe7CqYfSsc3a0Ny5QqhdclbBFpDuTYyboeMBp4UURaGWMO2qNdBugLRZTjDh3P5PkftzJ3XRytGwV4xj3VAHk58PuLsPRVaNgWJs7XJ5YpVQqvS9hAK+Az+zq2DzDTGDNfRL4QkX5YVeIxwK3Ohai8XVZuHh8vi+G/v+0gN99wz9lduT28a62r/q6Qw9tg9hTreeD9roPzX4AAfV+PUqXxuoRtjNkA9C+i/w0OhKPUKSKjD/PU91vYk5DG6F4hPDH2NNoH13c6rMrLz4cV/2fdruUfBFd/Cb0ucjoqpdyG1yVspWqrfYnpPD1/Cwu3xtO5WSCf3jSI8B4tnA6raiTFwtw7YM8S6H4BXPwWBHlI2ZSqIZqwlXJYcmYOb/+2k0/+iMHPV3j4gp5MGt7Jfd9T7coY633VCx4Ckw8XvQUDbnSb27WUqk00YSvlkNy8fCJWxfL6r9s5mp7N5QPa8tB5PQhpGOB0aFUjLRHm3wdb50G7oXDZ/0HTTk5HpZTb0oStlAN+336E537Ywvb4VAZ3aspnY0+jT5tGTodVdbbOh/n/hIxjMHoaDLsHfDygwZxSDtKErVQN2hGfwrM/bOX37UfoEFyf/7t+IOf1DnH/27QKpB+l15ZXIXKJ9XatG76z/iulKk0TtlI1IDE1izcW7uDrlfuoX9eXxy7sxQ1ndMC/jgeddW77Ab6/j+bpiRD+CIx4AHzd+NWeStUymrCVqkZZeYZ3InfybuQu0rPzuH5Ie+4d3Z2mgXWdDq3qpB+FH6fCxpkQEsqano8QFl7iU32VUhWgCVupapCbl883q/fz4pIMkrKiOadnCx4Z09MzHifqatsCq2FZeiKc9TCMeIDUZcudjkopj6QJW6kqZIzh583xvPTzNnYfSaNrYx/enziUwZ2aOh1a1Uo/Cj89bN2yFRIK130LrU53OiqlPJombKWqyIrdibzw0zbW7kuiS/NA3rthIHUPb/W8ZB39I3x/70ln1dTxoCp+pWopTdhKVdK2Q8m89FM0v207TMuGAbx4eSiXD2hLHV8fIo9sczq8qpOWYJ1Vb/wGQvroWbVSNUwTtlIVtCchjTcXbmfu+jga+Ndh6vk9mTiso2e8oMOVMbBhppWss1L0rFoph2jCVqqcYo+m89aiHXy39gB1fX2YMrIzt5/Vhcb1PTCBJe2D+ffDzl+h7SC4+L/QopfTUSnllTRhK1VGcUkZ/Pe3nXwTFYuPjzBxWEduO6sLzRv4Ox1a1cvPg5UfwKKnre4LXoJBt+jTypRykCZspUoRn5zJ24t3ErEyFoBrh7TnzlFdPeeZ34Ud3grz7ob9q6DraBj7OjRu73RUSnk9TdhKFeNwcibvLdnNl3/tJS/fcGVYO+46uyttGtdzOrTqkZsFS1+Dpa+CfwO47H04/Sp9s5ZStYQmbKUKOZCUwXu/7yJiVSx5+YZx/dtw99ndaB9c3+nQqk/sSuus+sg2CL0Szn8BAps5HZVSyoUmbKVsexLSeDdyJ9+tOYAIXDGwLbed1YUOwYFOh1Z9Mo7Bwqdg9afQsA1cOxO6n+d0VEqpImjCVl5v26Fk3l68ix82xOHn68P1QzswZWRnWntq1Tf8favWz49aSfuMOyH8YasqXClVK3ldwhaRAGAJ4I9V/m+NMU+KSFNgBtARiAGuMsYccypOVf3WxSbxzuKd/LIlnsC6vkwZ2YWbz+zkma2+XSXssN5VHbMU2oTBDbP1AShKuQGvS9hAFnC2MSZVRPyAZSLyIzAOWGSMeUFEHgYeBqY6Gaiqevn5ht+2Heb9pbtZuecojer5ce853bhpeEfPvI/aVU6G1ajsjzegTj248DUYeBP4+DgdmVKqDLwuYRtjDJBqd/rZfwa4BAi3+38GRKIJ22Nk5uQxZ+0BPli6m11H0mjTuB6PXdiLawa3J8jfC74GOxfBDw/AsT0QehWc9xwEtXA6KqVUOYiVv7yLiPgCq4GuwNvGmKkikmSMaewyzjFjTJMipp0CTAEICQkZGBERUaEYUlNTCQoKqtC07sqJMqdmG36LzWHh3lySsw0dGvpwQUc/wlr6Usen+m9Xcno71806StedH9HiyDLS67Vme/fbSGrSt1qX6XSZnaBlLp9Ro0atNsaEVXFIHs8rE3YBEWkMzAbuBpaVJWG7CgsLM1FRURVadmRkJOHh4RWa1l3VZJl3HUnls+UxfBO1n4ycPMJ7NGfKiM6c0SUYqcH7ih3bznk5sOI9iHwB8rKtZ38Pvxf8qv9hL7pve4fKlFlENGFXgBfUBRbPGJMkIpHA+UC8iLQyxhwUkVbAYWejU+WVl2+IjD7Mp8tjWLojgbq+PlzcrzWTR3SmR0svav28azH8OBUSoqHrP+CCFyG4i9NRKaUqyesStog0B3LsZF0PGA28CMwDJgAv2P/nOhelKo/j6Tl8szqWz//cy76j6YQ09OeBf3TnmsHtPb/Ft6ukffDzv2HrPGjSEcZHQPfz9UllSnkIr0vYQCvgM/s6tg8w0xgzX0T+BGaKyM3APuBKJ4NUpdt2KJnPlu9lztoDZOTkMbhjU6ae35Nze4fg5+tFLZ9zMmH5W1YLcICzH4Mz7q6R6m+lVM3xuoRtjNkA9C+ifyJwTs1HpMojLSuX+RvimL4ylnWxSfjX8eHSfm24cVgHerdu5HR4NcsYiP7Rek910l447VI491lo3M7pyJRS1cDrErZyTxv3H2f6qn3MWxdHalYuXVsE8diFvbh8QFuaBHr4/dNFSdhpJeqdv0LznnDjPOh8ltNRKaWqkSZsVWslZ+Ywd10cESv3sTkumQA/Hy4Mbc34we0Y2KFJjbb2rjXSj8LvL8GqD8CvPpz3PAyeDL5+TkemlKpmmrBVrZKTl8/SHUf4bs0Bft0ST1ZuPqe1asgzl/Tm4n5taFTPSxNTbjas+hB+fxGykmHABBj1qD78RCkvoglbOc4Yw8YDx/luzQG+Xx9HYlo2Ter7cfWgdlw+oC2nt23knWfTYF+nXgC/PA5Hd0HnUdZTykJ6Ox2ZUqqGacJWjok9ms689XHMXnuAnYdTqevrw+jTWnBZ/7ac1b05det4UUvvohzcYL1NK2YpNOsO134D3f6ht2kp5aU0YasaFXs0nR82HmTBxoNs2H8cgEEdm/D8uFDGhLby3ipvVymH4LdnYO1XUK8JjHkFBk7U69RKeTlN2Kra7Uu0kvSM5RnE/LQYgL7tGvPomJ5c0KcV7ZrWdzjCWiIz2bqf+s+3rUeLnnEnjHwI6jV2OjKlVC2gCVtVufx865r0oq3xLNx6mC0HkwHo3MhHk3RRcrNg1Uew9BVIT4Tel8HZj+vjRJVSJ9GErapEenYuf+xMZNHWeBZtO8yRlCx8BAZ2aHIiSe/asJLwkZqETsjPgw0zYfF/4Pg+6HQWjJ4GbQY4HZlSqhbShK0qxBhDdHwKy3YksHRHAn/tTiQrN58g/zqc1b055/RqwageLU56qMkuB+OtVYyBHb/Awqfg8GZo1RcufhO6nO10ZEqpWkwTtiqzQ8czWbYzgWU7jrBsZyIJqVkAdG4eyPjB7RndK4TBnZpq6+6SxK6ChU/C3j+gSSe4/CPoPQ58dJ0ppUqmCVsVyRjDvqPprIo5xqo9R1m19yi7j6QBEBxYl+Fdm3Fmt2ac2bUZrRvXczhaNxC3FhY/Dzt+hsDmVsvvAROgjhc+VlUpVSGasBUAmTl5bD2YzLrYJKJijrEq5iiHU6wz6Eb1/Ajr0ISrw9pxZrdm9GrZEB8fvRe4LAJT90DEB7BtPgQ0tt6kNeR28A9yOjSllJvRhO2FMnPyiD6UwoYDx9m0/zgbDhxne3wKefkGgDaN6zGsSzBhHZsyqGNTurUI0gRdXoe3QuTzDNoyF/wbQfijMPQ2CPCyN4oppaqMJmwPlp2bT0xiGtvjU9gen8qO+BS2x6cQk5h+Ijk3qe9HaNvGnN2zOaFtGnN620ZaxV0ZR7bD7y/Apu+gbhAxHa6i4zUvWQ9AUUqpStCE7caMMSSl53AgKYN9R9PZdzSdWJf/+49lkGsnZh+BDsGBdG0RxPl9WtKndSNC2zaiTeN63vuc7qp0JBqWvgobv4E69eDMf8Kwu4lZuYGOmqyVUlVAE7ZD8vIN6dm55OQZcvLyybX/Z+flk5aVS3JGLimZOaRk5pKcmUNyZi4JqVkcScnicEoWCSnW5+y8/JPm26S+H+2a1qd3m0aMCW1F95AGdAsJokvzIAL8fB0qrQeLW2cl6q3fg1896+lkw++DwGZOR6aU8jCasB1w6Hgmdy5KJ/OXn8s1XdPAurRo4E/zBv50aR5I8wb+tGgQQJvGAbRrWp92TevTMECfN10j9i63EvXOhdY16pEPWo3JAoOdjkwp5aE0YTtgc9xxMvPgpuEdadukPn6+gp+vj/0nBNatQ8N6fjQIqGP/+RHkXwdfbfjlLGNg5yIrUe9bDvWbwTlPwKBbtDGZUqraeV3CFpF2wOdASyAfeN8Y86aITAMmA0fsUR81xiyojhhiEtMBuPvsbjQN1Ptwa728XNj2PSx7Aw6ug4Zt4PwXYcCNUFefia6Uqhlel7CBXOABY8waEWkArBaRX+1hrxtjXqnuANo2qceQlr40qa/V17VaVgqs/RL+egeS9llPJrvoLeg7Xh94opSqcV6XsI0xB4GD9ucUEdkKtKnJGM7r3RL/IwHaOru2So6DFf8HUZ9C1nFoNwTO+w/0GAM+2nBPKeUMMcY4HYNjRKQjsAToA9wPTASSgSiss/BjRUwzBZgCEBISMjAiIqJCy05NTSUoyLuedlXbyxyUspu2++fS4vBSxBiONB/K/raXktyoR4XnWdvLXB20zN6hMmUeNWrUamNMWBWH5PG8NmGLSBDwO/CcMeY7EQkBEgADPAO0MsZMKmkeYWFhJioqqkLLj4yMJDw8vELTuqtaWea8XIheACvfh5il4BcIA26AobdDk46Vnn2tLHM10zJ7h8qUWUQ0YVeA11WJA4iIHzAL+MoY8x2AMSbeZfgHwHyHwlM1IfUwrPkMoj6B5APQqJ31LuqBE/WpZEqpWsnrErZYF44/ArYaY15z6d/Kvr4NcBmwyYn4VDUyBvavgpUfwObZkJ8DncNhzMvQ/Xy9Pq2UqtW8LmEDw4EbgI0iss7u9ygwXkT6YVWJxwC3OhGcqgZZKdazvaM+goPrwb8hDLrZun+6WTeno1NKqTLxuoRtjFkGFNU8u1ruuVYOKTibXvO5laxz0qB5L7jwNTj9an29pVLK7XhdwlYeLi0RNkRYifrINqsRWZ9xMGACtA0DvZVOKeWmNGEr95eXA7t+g/XTYet869p0mzDrISd9xoF/A6cjVEqpStOErdyTMXBgNWyYAZtmQXqi1bp70C3WbVkhvZ2OUCmlqpQmbOVeEnfBhplWoj62B3z9oecY67p0l3P0kaFKKY+lCVvVfkf3wNZ5sHkOxK0BBDqNsF5p2esifVOWUsoraMJWtVPCTtgyB7bMhUMbrH6t+sHopyD0SmhUo49/V0opx2nCVrWDMVZijv4RtsyDw5ut/m0HwbnPWmfSVfCoUKWUcleasJVzstNg9++w/SfY8QukHAQE2p9hvW+610V6Jq2UUjZN2KrmGAMJO2DXYtjxM+xZCnlZ1pPHuoyyHg/a9R8Q1NzpSJVSqtbRhO2ElEM0PL4NCHc6kuqXfBD2/A67f+eMrT/D74lW/+CuMHgydDvXOqPW1t1KKVUiTdhOWPM5A9Y+B2NvBl8/p6OpWsf3Q+wK2PeXVd2dEG31rx/M8UY9aTHkSuh8FjTt7GycSinlZjRhO6Gu/RzrrBSo39TZWCojLxfiN0HsSoj9C/atgOT91jC/QOhwhvUQk05nQUgftixZQouwcEdDVkopd6UJ2wkFL57ITnWfhJ2XYz2b++B6iFtn/T+0EXIzrOENWkP7IdDubut/SCj46u6llFJVRY+oTjhxhp3qbBxFyc+H4/vgyHYrQSdEQ/wWiN9sNRADK/6Wp8PAidBmoJWgG7XTF2sopVQ10oTthIKXUWQ7lLBzs62q62N7IWkvJO2zPidst1pxF5w1AwQ2h+Y9YcgU68ElrfpZ1599fJyJXSmlvJQmbCcUnGEfXA/1mloJ3L8B+NWr2FlqTqZ1PTwr2frLTIbMJEg9bP2lHf77c8ohSIkDk//39OILjdpaLbc7joDm3a0k3ay7+1TZK6WUh9OE7YSgFtb/BQ+e3F98rWTuWwd8/MCnjv25DiDWayPzcu3/OZCfC7mZkJddwsIEAptBUIh1ttysGzRub/91gCYdrOvPer1ZKaVqNT1KOyG4C1EDXyesRxvrzDjzuH2GnGJVk+fn/p2QCz5jrCTuW5DI/azuOnWtB48ENLLP1BtCQEPrf1AI1A/WZKyUUh5Aj+QOSW3QGbqHOx2GUkopN+F1LYdEpJ2ILBaRrSKyWUTutfs3FZFfRWSH/b+J07EqpZRSBbwuYQO5wAPGmF7AUOBOETkNeBhYZIzpBiyyu5VSSqlawesStjHmoDFmjf05BdgKtAEuAT6zR/sMuNSRAJVSSqkiiDHG6RgcIyIdgSVAH2CfMaaxy7BjxphTqsVFZAowBSAkJGRgREREhZadmppKUFBQhaZ1V1pm76Bl9g6VKfOoUaNWG2PCqjgkj+e1jc5EJAiYBdxnjEmWMt7/bIx5H3gfICwszISHh1do+ZGRkVR0WnelZfYOWmbv4I1ldprXVYkDiIgfVrL+yhjznd07XkRa2cNbAYedik8ppZQqzOsStlin0h8BW40xr7kMmgdMsD9PAObWdGxKKaVUcbyxSnw4cAOwUUTW2f0eBV4AZorIzcA+4EpnwlNKKaVO5dWNzipLRI4Aeys4eTMgoQrDcQdaZu+gZfYOlSlzB2NM86oMxhtownaIiER5WytJLbN30DJ7B28ss9O87hq2Ukop5Y40YSullFJuQBO2c953OgAHaJm9g5bZO3hjmR2l17CVUkopN6Bn2EoppZQb0IStlFJKuQFN2A4QkfNFJFpEdoqIR77G01vfOy4iviKyVkTm292eXt7GIvKtiGyzt/UZXlDmf9r79CYRmS4iAZ5WZhH5WEQOi8gml37FllFEHrGPZ9Eicp4zUXs+Tdg1TER8gbeBC4DTgPH2+7g9jbe+d/xerFe2FvD08r4J/GSM6Qn0xSq7x5ZZRNoA9wBhxpg+gC9wDZ5X5k+B8wv1K7KM9vf6GqC3Pc079nFOVTFN2DVvMLDTGLPbGJMNRGC9i9ujeON7x0WkLXAh8KFLb08ub0NgJNaz+THGZBtjkvDgMtvqAPVEpA5QH4jDw8psjFkCHC3Uu7gyXgJEGGOyjDF7gJ1YxzlVxTRh17w2QKxL9367n8ey3zveH1gBhBhjDoKV1IEWDoZW1d4A/gXku/Tz5PJ2Bo4An9iXAT4UkUA8uMzGmAPAK1jvGzgIHDfG/IIHl9lFcWX0umOaUzRh17yiXrztsffWFX7vuNPxVBcRGQscNsasdjqWGlQHGAC8a4zpD6Th/lXBJbKv214CdAJaA4Eicr2zUTnOq45pTtKEXfP2A+1cuttiVal5HC977/hw4GIRicG6zHG2iHyJ55YXrH15vzFmhd39LVYC9+Qyjwb2GGOOGGNygO+AYXh2mQsUV0avOaY5TRN2zVsFdBORTiJSF6uxxjyHY6py3vbecWPMI8aYtsaYjljb9DdjzPV4aHkBjDGHgFgR6WH3OgfYggeXGasqfKiI1Lf38XOw2md4cpkLFFfGecA1IuIvIp2AbsBKB+LzePqkMweIyBis652+wMfGmOecjajqiciZwFJgI39f030U6zr2TKA99nvHjTGFG7e4NREJBx40xowVkWA8uLwi0g+rkV1dYDdwE9aJgCeX+Sngaqw7IdYCtwBBeFCZRWQ6EI71Cs144ElgDsWUUUT+DUzCWif3GWN+rPmoPZ8mbKWUUsoNaJW4Ukop5QY0YSullFJuQBO2Ukop5QY0YSullFJuQBO2Ukop5QY0YSullFJuQBO2Ukop5QY0YSvlYUQkVET2isjtTseilKo6mrCV8jDGmI1Yj0e90elYlFJVRxO2Up7pMNDb6SCUUlVHE7ZSnukFwF9EOjgdiFKqamjCVsrDiMj5QCDwA3qWrZTH0IStlAcRkQDgJeAOrDel9XE2IqVUVdGErZRneQz43BgTgyZspTyKJmylPISI9AD+gfWuddCErZRH0fdhK6WUUm5Az7CVUkopN6AJWymllHIDmrCVUkopN6AJWymllHIDmrCVUkopN6AJWymllHIDmrCVUkopN/D/GjxX8sKLb/MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal λ for Fold 1 is 3.9000000000000004\n"
     ]
    }
   ],
   "source": [
    "plt.title(\"Plot of MSE errors for over different penalty terms for Ridge Regression [Fold 1]\")\n",
    "plt.plot(lambda_vec, train_MSE[1], label = \"Training Errors\")\n",
    "plt.plot(lambda_vec, val_MSE[1], label = \"Validation Errors\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"$\\lambda$\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()\n",
    "print(\"Optimal λ for Fold 1 is \" + str(lambda_vec[np.argmin(val_MSE[1])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-hybrid",
   "metadata": {},
   "source": [
    "Note that the optimal $\\lambda$ for each fold is obtained by taking the index of the minimum of the validation MSE, and using that index to find the corresponding lambda.\n",
    "\n",
    "This is done for each of the five folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "widespread-denial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal λ for Fold 1 is 3.9000000000000004\n",
      "Optimal λ for Fold 2 is 0.1\n",
      "Optimal λ for Fold 3 is 13.3\n",
      "Optimal λ for Fold 4 is 17.0\n",
      "Optimal λ for Fold 5 is 0.1\n"
     ]
    }
   ],
   "source": [
    "# The optimal lambdas for for each fold obtained using argmin\n",
    "for i in range(0,5):\n",
    "    print(\"Optimal λ for Fold \" + str(i+1) + \" is \" + str(lambda_vec[np.argmin(val_MSE[i+1])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-reform",
   "metadata": {},
   "source": [
    "#### Question 1.2.2\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-basics",
   "metadata": {},
   "source": [
    "In order to compute the average in-sample and out-of-sample MSEs, we first need to obtain the optimal $\\lambda$ out of all the folds.\n",
    "\n",
    "This is done by computing the average validation MSE over all the folds for each $\\lambda$, and then finding the minimum over this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "necessary-cancer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal lambda is: 1.3\n"
     ]
    }
   ],
   "source": [
    "# Compute the average validation MSE over the folds, to get average for each penalty term\n",
    "average_val_MSE = np.mean([val_MSE[fold] for fold in range(1, 6)], axis = 0)\n",
    "optimal_lambda = lambda_vec[np.argmin(average_val_MSE)]\n",
    "print(\"The optimal lambda is: \" + str(optimal_lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-review",
   "metadata": {},
   "source": [
    "We then train the model over the whole of the training data using this optimal lambda parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "matched-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_ridge = ridge_estimate(X_train, Y_train, penalty=optimal_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-terrorism",
   "metadata": {},
   "source": [
    "The resulting MSEs are obtained below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "horizontal-blink",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge - In sample error    : 24.559828320867624\n",
      "Ridge - Out of sample error: 19.360934376274972\n"
     ]
    }
   ],
   "source": [
    "# in sample MSE\n",
    "train_preds_ridge = predict_with_estimate(X_train, beta_ridge)\n",
    "MSE_train_ridge = np.mean((Y_train - train_preds_ridge) ** 2)\n",
    "\n",
    "# out of sample MSE\n",
    "test_preds_ridge = predict_with_estimate(X_test, beta_ridge)\n",
    "MSE_test_ridge = np.mean((Y_test - test_preds_ridge) ** 2)\n",
    "\n",
    "print(\"Ridge - In sample error    : \" + str(MSE_train_ridge))\n",
    "print(\"Ridge - Out of sample error: \" + str(MSE_test_ridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-python",
   "metadata": {},
   "source": [
    "For comparsion, the MSEs obtained via linear regression are as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "forward-genealogy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - In sample error    : 24.38006444485437\n",
      "Linear Regression - Out of sample error: 19.525828624573784\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression - In sample error    : \" + str(MSE_train))\n",
    "print(\"Linear Regression - Out of sample error: \" + str(MSE_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-round",
   "metadata": {},
   "source": [
    "Thus we can see that both the methods produce very similar results, with the ridge regression obtaining slightly out-of-sample MSE (which is the target we are interested in)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-spiritual",
   "metadata": {},
   "source": [
    "The ridge regression model has a penalty term whose effect is to try and keep the coefficients small, and the benefit of this is that there can be lower variance in the model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-fiber",
   "metadata": {},
   "source": [
    "We do indeed observer that the the coefficients (the beta vector for ridge) are smaller:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "signed-cookbook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear Regression Parameters</th>\n",
       "      <th>Ridge Regression Parameters</th>\n",
       "      <th>Absolute Difference in Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>β_0</th>\n",
       "      <td>22.521</td>\n",
       "      <td>22.455</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_1</th>\n",
       "      <td>-0.624</td>\n",
       "      <td>-0.636</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_2</th>\n",
       "      <td>5071.913</td>\n",
       "      <td>0.572</td>\n",
       "      <td>5071.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_3</th>\n",
       "      <td>-35510.064</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>35509.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_4</th>\n",
       "      <td>35509.889</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>35509.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_5</th>\n",
       "      <td>1394964953.358</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>1394964954.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_6</th>\n",
       "      <td>979.428</td>\n",
       "      <td>1.585</td>\n",
       "      <td>977.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_7</th>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_8</th>\n",
       "      <td>1202.083</td>\n",
       "      <td>-1.732</td>\n",
       "      <td>1203.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_9</th>\n",
       "      <td>-976.306</td>\n",
       "      <td>1.56</td>\n",
       "      <td>977.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_10</th>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_11</th>\n",
       "      <td>-6129.348</td>\n",
       "      <td>-0.872</td>\n",
       "      <td>6128.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_12</th>\n",
       "      <td>0.749</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_13</th>\n",
       "      <td>-3.715</td>\n",
       "      <td>-3.634</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_14</th>\n",
       "      <td>-1394964955.129</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>1394964954.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_15</th>\n",
       "      <td>6127.612</td>\n",
       "      <td>-0.872</td>\n",
       "      <td>6128.483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_16</th>\n",
       "      <td>-5070.779</td>\n",
       "      <td>0.572</td>\n",
       "      <td>5071.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_17</th>\n",
       "      <td>-1205.581</td>\n",
       "      <td>-1.733</td>\n",
       "      <td>1203.847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Linear Regression Parameters  Ridge Regression Parameters  \\\n",
       "β_0                         22.521                       22.455   \n",
       "β_1                         -0.624                       -0.636   \n",
       "β_2                       5071.913                        0.572   \n",
       "β_3                     -35510.064                         -0.1   \n",
       "β_4                      35509.889                         -0.1   \n",
       "β_5                 1394964953.358                        -0.84   \n",
       "β_6                        979.428                        1.585   \n",
       "β_7                         -0.164                       -0.148   \n",
       "β_8                       1202.083                       -1.732   \n",
       "β_9                       -976.306                         1.56   \n",
       "β_10                         -0.05                       -0.092   \n",
       "β_11                     -6129.348                       -0.872   \n",
       "β_12                         0.749                         0.82   \n",
       "β_13                        -3.715                       -3.634   \n",
       "β_14               -1394964955.129                        -0.84   \n",
       "β_15                      6127.612                       -0.872   \n",
       "β_16                     -5070.779                        0.572   \n",
       "β_17                     -1205.581                       -1.733   \n",
       "\n",
       "      Absolute Difference in Parameters  \n",
       "β_0                               0.065  \n",
       "β_1                               0.012  \n",
       "β_2                             5071.34  \n",
       "β_3                           35509.963  \n",
       "β_4                           35509.988  \n",
       "β_5                      1394964954.198  \n",
       "β_6                             977.842  \n",
       "β_7                               0.017  \n",
       "β_8                            1203.814  \n",
       "β_9                             977.866  \n",
       "β_10                              0.042  \n",
       "β_11                           6128.475  \n",
       "β_12                              0.071  \n",
       "β_13                              0.081  \n",
       "β_14                     1394964954.289  \n",
       "β_15                           6128.483  \n",
       "β_16                           5071.351  \n",
       "β_17                           1203.847  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Differences observed in parameters\n",
    "abs_diff_beta = np.abs(beta_ml - beta_ridge)\n",
    "\n",
    "df_beta_parameters = pd.DataFrame(columns=['Linear Regression Parameters', \n",
    "                                           'Ridge Regression Parameters',\n",
    "                                           'Absolute Difference in Parameters'],\n",
    "                                  index=[['β_%s' %i for i in range(18)]],\n",
    "                                  data = np.array([beta_ml, beta_ridge, abs_diff_beta]).T)\n",
    "\n",
    "pd.set_option('display.float_format', str)\n",
    "\n",
    "df_beta_parameters.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-grounds",
   "metadata": {},
   "source": [
    "In particular, ridge regression is advantageous in the cases where many predictors are collinear with eachother, however if this is not the case then ridge may not provide any significant advantage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-field",
   "metadata": {},
   "source": [
    "We can investigate this collinearity using a correlation matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "random-master",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Correlation Matrix\n",
    "corr_mat = pd.DataFrame(X_train).corr()\n",
    "sns.heatmap(np.array(corr_mat)[1:, 1:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-fellowship",
   "metadata": {},
   "source": [
    "Here, the lighter squares correspond to precitors being very correlated.\n",
    "We have excluded the column of ones here, and we observe that apart from the diagonal, there only seem to be very few highly correlated predictors. For example on the diagram we can observe predictors 1 and 15 appear to be highly correlated.\n",
    "\n",
    "However the vast majority are much darker, suggesting that there is not a significant amount of collinearity present in general. And hence ridge regression can only provide a small advantage (as seen by the lower MSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-nirvana",
   "metadata": {},
   "source": [
    "### 1.3 Regression with $k$ nearest neighbours ($knn$)\n",
    "***\n",
    "\n",
    "#### Question 1.3.1\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-software",
   "metadata": {},
   "source": [
    "Firstly, we begin by making our knn algorithm.\n",
    "\n",
    "The k nearest neighbours algorithm works by computing the distances between a given test set and the samples from the training set. It then selects the $k$ nearest neighbours to each point in the test set, and in the case of regression, averages these values in the neighbourhood to form a prediciton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "piano-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance function for kNN\n",
    "def euclidian_distance(p, q):\n",
    "    return np.sqrt(np.sum((q-p)**2, axis = 1))\n",
    "\n",
    "# function to find the k nearest neighbours in the training set given a test set\n",
    "def k_neighbours(X_train, X_test, k=5, return_distance=False):\n",
    "    dist = []\n",
    "    neigh_ind = []\n",
    "    \n",
    "    # compute distance from each point x_text in X_test to all points in X_train \n",
    "    point_dist =  [euclidian_distance(x_test, X_train) for x_test in X_test]\n",
    "    \n",
    "    # determine which k training points are closest to each test point\n",
    "    for row in point_dist:\n",
    "        enum_neigh = enumerate(row)\n",
    "        sorted_neigh = sorted(enum_neigh, key=lambda x: x[1])[:k]\n",
    "    \n",
    "        ind_list = [tup[0] for tup in sorted_neigh]\n",
    "        dist_list = [tup[1] for tup in sorted_neigh]\n",
    "    \n",
    "        dist.append(dist_list)\n",
    "        neigh_ind.append(ind_list)\n",
    "    \n",
    "    # return distances together with indices of k nearest neighbours\n",
    "    if return_distance:\n",
    "        return np.array(dist), np.array(neigh_ind)\n",
    "    \n",
    "    return np.array(neigh_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "amateur-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to predict the values of the test points.\n",
    "def reg_predict(X_train, Y_train, X_test, k):\n",
    "    # each of the k neighbours contributes equally to the classification of any data point in X_test  \n",
    "    neighbours = k_neighbours(X_train, X_test, k=k)\n",
    "    # compute mean over neighbours labels \n",
    "    Y_pred = np.array([np.mean(Y_train[neighbour]) for neighbour in neighbours])\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-coordinator",
   "metadata": {},
   "source": [
    "Finally, we need a measure of how well the model predicts the y values.\n",
    "For this we use the $R^2$ score.\n",
    "\n",
    "$$\n",
    "R^2(y, \\hat{y}) = 1 - \\frac{\\sum_{i=1}^n (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2} \\, ,\n",
    "$$\n",
    "where $\\bar{y} = \\frac{1}{n} \\sum_{i=1}^n y_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "hidden-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that calculates the R2 score given the predictions and actual values\n",
    "def r2_score(y_test, y_pred):\n",
    "    numerator = np.sum((y_test - y_pred)**2)\n",
    "    y_avg = np.mean(y_test)\n",
    "    denominator = np.sum((y_test - y_avg)**2)\n",
    "    return 1 - numerator/denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-jurisdiction",
   "metadata": {},
   "source": [
    "Again, in order to scan the optimal parameter term (in this case $k$), we create a vector of different possible values from 1 to 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "executive-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vec = np.arange(50)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "authorized-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_evaluate_kNN(folds, k_vec):\n",
    "    \n",
    "    # create dictionaries\n",
    "    train_MSE = {1:[], 2:[], 3:[], 4:[], 5:[]}\n",
    "    val_MSE = {1:[], 2:[], 3:[], 4:[], 5:[]}\n",
    "\n",
    "    for i in range(len(folds)):\n",
    "      \n",
    "        print('Fold', i+1)\n",
    "        # define the training set (i.e. selecting all folds and deleting the one used for validation)\n",
    "        train_set = np.delete(np.asarray(folds).reshape(len(folds), folds[0].shape[0], folds[0].shape[1]), i, axis=0)\n",
    "        train_folds = train_set.reshape(len(train_set)*train_set[0].shape[0], train_set[0].shape[1])\n",
    "        X_train = train_folds[:,:-1]\n",
    "        y_train = train_folds[:, -1]\n",
    "        \n",
    "        # define the validation set\n",
    "        val_fold = folds[i]\n",
    "        X_val = val_fold[:,:-1]\n",
    "        y_val = val_fold[:, -1]\n",
    "    \n",
    "        # train the model and obtain the parameters for each k\n",
    "        for k_param in k_vec:                        \n",
    "            train_preds_kNN = reg_predict(X_train, y_train, X_train, k_param)\n",
    "            val_preds_kNN = reg_predict(X_train, y_train, X_val, k_param)\n",
    "            \n",
    "            # evaluate\n",
    "            # training data MSE\n",
    "            MSE_train_kNN = np.mean((y_train - train_preds_kNN) ** 2)\n",
    "            \n",
    "            # validation data MSE\n",
    "            MSE_val_kNN = np.mean((y_val - val_preds_kNN) ** 2)\n",
    "            \n",
    "            # store these in the appropriate dictionaries\n",
    "            train_MSE[i+1].append(MSE_train_kNN)\n",
    "            val_MSE[i+1].append(MSE_val_kNN)\n",
    "    \n",
    "   \n",
    "    print(\"Training finished.\")\n",
    "    return train_MSE, val_MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-teddy",
   "metadata": {},
   "source": [
    "As before, we create a function that has one loop through the set of folds and another loop over the vector of $k$s, and applies the kNN model for wach combination\n",
    "\n",
    "The training and validation MSEs are also computed similarly and stored in dictionaries again:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-child",
   "metadata": {},
   "source": [
    "Perform the cross validation for each parameter value as required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "attended-springer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "train_MSE_kNN, val_MSE_kNN = cross_val_evaluate_kNN(folds, k_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-prague",
   "metadata": {},
   "source": [
    "Again, consider Fold 1 from our set of folds.\n",
    "We see in the function above that for this fold, a new model is created for each $k$, and the two MSEs are computed.\n",
    "These can then be plotted as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "complete-double",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Plot of MSE errors for over different k values for kNN [Fold 1]\")\n",
    "plt.plot(k_vec, train_MSE_kNN[1], label = \"Training Errors\")\n",
    "plt.plot(k_vec, val_MSE_kNN[1], label = \"Validation Errors\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-platform",
   "metadata": {},
   "source": [
    "From the plot we can see that the training MSE is a strictly increasing function of k, however for the validation error, there appears to be a minimum in the MSE between 0 and 10.\n",
    "\n",
    "We can obtain the optimal $k$ at which this happens using the \"argmin\" function as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "crude-receiver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal k for Fold 1 is 6\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal k for Fold 1 is \" + str(k_vec[np.argmin(val_MSE_kNN[1])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-switzerland",
   "metadata": {},
   "source": [
    "Similarly, the optimal parameter for each of the five folds are obtained below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "affecting-large",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal k for Fold 1 is 6\n",
      "Optimal k for Fold 2 is 2\n",
      "Optimal k for Fold 3 is 5\n",
      "Optimal k for Fold 4 is 4\n",
      "Optimal k for Fold 5 is 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    print(\"Optimal k for Fold \" + str(i+1) + \" is \" + str(k_vec[np.argmin(val_MSE_kNN[i+1])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-brother",
   "metadata": {},
   "source": [
    "In terms of the distribution of errors, it makes sense that there will be an optimal $k$ corresponding to a local minimum of the validation MSE. \n",
    "\n",
    "For very small $k$, we expect the model to perform very well for the training set (as each prediction has the actual value as one of the few neighbours), however it is also likely overfit to this set, and as a result it will not be generalisable to any new set (such as the validation set)\n",
    "\n",
    "In contrast, if $k$ is very large, then the model will no longer be very local as many neighbours will be selected for each point. Thus, this will no longer perform well for either the training or the validation set.\n",
    "\n",
    "And thus we expect there to be a minimum value of k that is small, but not small enough to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-dallas",
   "metadata": {},
   "source": [
    "#### Question 1.3.1\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-ceremony",
   "metadata": {},
   "source": [
    "Next, we find the optimal value of k over all of the folds as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "included-fever",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal k overall is: 2\n"
     ]
    }
   ],
   "source": [
    "# Compute the average validation MSE over the folds, to get average for each penalty term\n",
    "average_val_MSE_kNN = np.mean([val_MSE_kNN[fold] for fold in range(1, 6)], axis = 0)\n",
    "optimal_k = k_vec[np.argmin(average_val_MSE_kNN)]\n",
    "print(\"The optimal k overall is: \" + str(optimal_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-custom",
   "metadata": {},
   "source": [
    "We then use this to train the model over the whole training dataset using the optimal $k$, and then obtain the in-sample and out-of-sample MSEs using the training and the test data respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "yellow-happening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-val kNN - In sample error        : 3.973725247524753\n",
      "Cross-val kNN - Out of sample error    : 13.935808823529408\n"
     ]
    }
   ],
   "source": [
    "# in sample MSE\n",
    "train_preds_kNN = reg_predict(X_train, Y_train, X_train, optimal_k)\n",
    "MSE_train_kNN = np.mean((Y_train - train_preds_kNN) ** 2)\n",
    "\n",
    "# out of sample MSE\n",
    "test_preds_kNN = reg_predict(X_train, Y_train, X_test, optimal_k)\n",
    "MSE_test_kNN = np.mean((Y_test - test_preds_kNN) ** 2)\n",
    "\n",
    "print(\"Cross-val kNN - In sample error        : \" + str(MSE_train_kNN))\n",
    "print(\"Cross-val kNN - Out of sample error    : \" + str(MSE_test_kNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-scenario",
   "metadata": {},
   "source": [
    "And we can also get a measure of the accuracies using the $R^2$ score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "broke-cross",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-val kNN Train set mean accuracy  : 0.9557419532102102\n",
      "Cross-val kNN Test set mean accuracy   : 0.7619048240726203\n"
     ]
    }
   ],
   "source": [
    "print('Cross-val kNN Train set mean accuracy  :', r2_score(Y_train, train_preds_kNN))\n",
    "print('Cross-val kNN Test set mean accuracy   :', r2_score(Y_test, test_preds_kNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-premiere",
   "metadata": {},
   "source": [
    "The MSE values for each of the 3 models are summarised below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "popular-helping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>24.38006444485437</td>\n",
       "      <td>19.525828624573784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>24.559828320867624</td>\n",
       "      <td>19.360934376274972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kNN</th>\n",
       "      <td>3.973725247524753</td>\n",
       "      <td>13.935808823529408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Training         Validation\n",
       "Linear Regression  24.38006444485437 19.525828624573784\n",
       "Ridge Regression  24.559828320867624 19.360934376274972\n",
       "kNN                3.973725247524753 13.935808823529408"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_MSE = np.array([[MSE_train, MSE_test],[MSE_train_ridge, MSE_test_ridge], [MSE_train_kNN, MSE_test_kNN]])\n",
    "reg_MSE_df = pd.DataFrame(reg_MSE, columns = [\"Training\", \"Validation\"], index = [\"Linear Regression\", \"Ridge Regression\", \"kNN\"])\n",
    "reg_MSE_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-supervisor",
   "metadata": {},
   "source": [
    "Thus we see that the kNN model appears to have a much higher performance when comparing the Validation MSEs.\n",
    "This could be explained by the fact that the Linear and Ridge regression models require the assumption of linearity in the data, however as kNN is a local model, it can also deal with any non-linearity which may be present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-candidate",
   "metadata": {},
   "source": [
    "Furthermore, as we have no other information about the data, we are unsure if the data is homogeneous or not (that is drawn from a single or similar populations).\n",
    "\n",
    "The fact that the regression models performed slighlty worse may suggest that there is some inhomogeneity iand so one regression model for all the data might not be suitable. One possible way we could deal with an inhomogeneous data set, is by fitting different models over different regions, for example various kNN models for particular regions, each with an optimal $k$ for that area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-livestock",
   "metadata": {},
   "source": [
    "## Task 2: Classification\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-charlotte",
   "metadata": {},
   "source": [
    "### 2.1 Logistic Regression\n",
    "***\n",
    "\n",
    "#### Question 2.1.1\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-municipality",
   "metadata": {},
   "source": [
    "We start by importing the data used for the classification task, separating them into X and Y sets and creating panda dataframes and numpy arrays for use as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "controversial-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./classification_test.csv', header=None)\n",
    "train_data = pd.read_csv('./classification_train.csv', header=None)\n",
    "\n",
    "# Create DataFrames\n",
    "df_X_train = train_data[train_data.columns[:-1]]\n",
    "df_Y_train = train_data[train_data.columns[-1]]\n",
    "\n",
    "df_X_test = test_data[test_data.columns[:-1]]\n",
    "df_Y_test = test_data[test_data.columns[-1]]\n",
    "\n",
    "# Create Numpy Arrays\n",
    "X_train = np.array(train_data.iloc[:,:-1])\n",
    "Y_train = np.array(train_data.iloc()[:,-1])\n",
    "\n",
    "X_test = np.array(test_data.iloc[:,:-1])\n",
    "Y_test = np.array(test_data.iloc()[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-edition",
   "metadata": {},
   "source": [
    "Again, we can examine the structure of the data to get a better idea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "extra-vatican",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.16176470588235292</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.36315615714757354</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33333333333333326</td>\n",
       "      <td>0.33333333333333326</td>\n",
       "      <td>0.26785714285714285</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4705882352941176</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8587542643336633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33333333333333326</td>\n",
       "      <td>0.6666666666666667</td>\n",
       "      <td>0.6666666666666665</td>\n",
       "      <td>0.4285714285714285</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1176470588235294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1380543633762518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33333333333333326</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33333333333333326</td>\n",
       "      <td>0.26785714285714285</td>\n",
       "      <td>0.6666666666666665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4705882352941176</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.17585561791570375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33333333333333326</td>\n",
       "      <td>0.6666666666666665</td>\n",
       "      <td>0.41071428571428575</td>\n",
       "      <td>0.6666666666666665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6470588235294117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2396280400572246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6666666666666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0892857142857143</td>\n",
       "      <td>0.6666666666666665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0    1                   2    3   4                   5   \\\n",
       "0 0.16176470588235292 0.25 0.36315615714757354 0.25 0.0                 0.0   \n",
       "1  0.4705882352941176  0.5  0.8587542643336633  0.0 0.0 0.33333333333333326   \n",
       "2  0.1176470588235294  0.0  0.1380543633762518  0.0 1.0 0.33333333333333326   \n",
       "3  0.4705882352941176  0.5 0.17585561791570375  0.0 1.0                 1.0   \n",
       "4  0.6470588235294117  0.0  0.2396280400572246  0.0 1.0  0.6666666666666667   \n",
       "\n",
       "                   6                   7                   8   \\\n",
       "0 0.33333333333333326 0.33333333333333326 0.26785714285714285   \n",
       "1  0.6666666666666667  0.6666666666666665  0.4285714285714285   \n",
       "2                 1.0 0.33333333333333326 0.26785714285714285   \n",
       "3 0.33333333333333326  0.6666666666666665 0.41071428571428575   \n",
       "4                 1.0                 1.0  0.0892857142857143   \n",
       "\n",
       "                  9   10  11  \n",
       "0                1.0 1.0 0.0  \n",
       "1                1.0 0.0 1.0  \n",
       "2 0.6666666666666665 0.0 1.0  \n",
       "3 0.6666666666666665 0.0 0.0  \n",
       "4 0.6666666666666665 0.0 0.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eastern-allah",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-momentum",
   "metadata": {},
   "source": [
    "The last column consists only of 1s and 0s, these are the two classes we use for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-corner",
   "metadata": {},
   "source": [
    "Now we start considering the logistic regression model. \n",
    "This involves assuming there exists a linear relationship between the predictors and the log-odds of the classifcation events:\n",
    "\n",
    "$$\\mathbf{x}^T \\mathbf{\\beta} = \\log{\\frac{P(y=1)}{1-P(y=1)}}$$\n",
    "\n",
    "And as we saw in lectures, we can rearrange this to be in the form of the logistic function:\n",
    "$$P(y=1) = \\frac{1}{1 + e^{-\\mathbf{x}^T \\mathbf{\\beta}}} =: h_{\\mathbf{\\beta}}(\\mathbf{x})$$\n",
    "\n",
    "We create this logistic function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "transparent-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-bristol",
   "metadata": {},
   "source": [
    "We also create function that computes the output of the logistic function for a new data point $X$, given the parameters $\\beta$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "specific-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute y log\n",
    "def predict_log(X, beta, beta_0):\n",
    "    y_log = logistic(beta.T @ X + beta_0)\n",
    "    return y_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-sentence",
   "metadata": {},
   "source": [
    "Our aim is to obtain the optimal parameters $\\beta$.\n",
    "We approach this by first initialising them to be zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "danish-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialise beta and beta_0\n",
    "def initialise(d):\n",
    "    beta = np.zeros(shape=(d, 1), dtype=np.float32)\n",
    "    beta_0 = 0\n",
    "\n",
    "    return beta, beta_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-flush",
   "metadata": {},
   "source": [
    "We then want to maximise the log-likelihood of the model over the training set.\n",
    "(Note that this step requires the assumption of independence in the samples).\n",
    "\n",
    "As explained in the lectures, this is equivalent to minising the cost function:\n",
    "$$\n",
    "\\mathcal L = - \\frac{1}{n} \\sum_{i=1}^n y^{(i)} \\log(\\hat{y}_{\\text{log}}^{(i)}) + (1-y^{(i)}) \\log (1-\\hat{y}_{\\text{log}}^{(i)}) \\, .\n",
    "$$\n",
    "\n",
    "Whose derivatives are:\n",
    "$$\n",
    "\\frac{\\partial \\mathcal L}{\\partial \\boldsymbol \\beta} = \\frac{1}{n} \\sum_{i=1}^n X^{(i)} (\\hat{y}_{\\text{log}}^{(i)} - y^{(i)})^T\n",
    "$$\n",
    " \n",
    "$$\n",
    "\\frac{\\partial \\mathcal L}{\\partial \\beta_0} = \\frac{1}{n} \\sum_{i=1}^n (\\hat{y}_{\\text{log}}^{(i)} - y^{(i)})\n",
    "$$\n",
    "\n",
    "This is implemented with the following functions: 'propagate' and and 'optimise'.\n",
    "The 'propagate' function computes and returns the above gradients and the cost function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "institutional-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass of cost function and its derivatives\n",
    "def propagate(X, y, beta, beta_0):\n",
    "  \"\"\"\n",
    "  Arguments:\n",
    "  X: data of size (d, n)\n",
    "  y: true label vector of size (1, n)\n",
    "  beta: parameters, a numpy array of size (d, 1)\n",
    "  beta_0: offset, a scalar\n",
    "\n",
    "  Returns:\n",
    "  cost: negative log-likelihood cost for logistic regression\n",
    "  dbeta: gradient of the loss with respect to beta\n",
    "  dbeta_0: gradient of the loss with respect to beta_0\n",
    "  \"\"\"\n",
    "  n = X.shape[1]\n",
    "  y_log = predict_log(X, beta, beta_0)\n",
    "\n",
    "  # cost function\n",
    "  cost = (-1) * np.mean(np.multiply(y, np.log(y_log)) + np.multiply((1-y), np.log(1-y_log)), axis = 1) \n",
    "\n",
    "  # derivatives\n",
    "  dbeta = (1/n) * X @ (y_log - y).T\n",
    "  dbeta_0 =  np.mean(y_log - y, axis = 1)\n",
    "\n",
    "  assert(dbeta.shape==beta.shape)\n",
    "  assert(dbeta_0.dtype==float)\n",
    "  cost = np.squeeze(cost)\n",
    "  assert(cost.shape==())\n",
    "  \n",
    "  # store gradients in a dictionary\n",
    "  grads = {\"dbeta\": dbeta, \"dbeta_0\": dbeta_0}\n",
    "  \n",
    "  return grads, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-token",
   "metadata": {},
   "source": [
    "The 'optimise' function then performs the optimisation by retrieving these values by calling the 'propagate' function, and then updating our guess for the 'betas' according to the updating procedure and the learning rate $\\alpha$:\n",
    "\n",
    "$$\n",
    "\\boldsymbol \\beta = \\boldsymbol \\beta - \\alpha \\ \\frac{\\partial \\mathcal L}{\\partial \\boldsymbol \\beta}\n",
    "$$\n",
    "$$\n",
    "\\beta_0 = \\beta_0 - \\alpha \\ \\frac{\\partial \\mathcal L}{\\partial \\beta_0} \\, .\n",
    "$$\n",
    "\n",
    "This procedure is repeated until the maximum number of iterations specified is reached:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "legitimate-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that performs the optimisation of the cost function as required\n",
    "def optimise(X, y, beta, beta_0, num_iterations=1000, learning_rate=0.005, print_cost=False):\n",
    "  \"\"\"\n",
    "  Arguments:\n",
    "  X: data of size (d, n)\n",
    "  y: true label vector of size (1, n)\n",
    "  beta: parameters, a numpy array of size (d, 1)\n",
    "  beta_0: offset, a scalar\n",
    "  num_iterations: number of iterations gradient descent shall update the parameters\n",
    "  learning_rate: step size in updating procedure\n",
    "  print_cost: whether to print the cost every 100 iterations or not\n",
    "\n",
    "  Returns:\n",
    "  params: dictionary containing the parameters beta and offset beta_0\n",
    "  grads: dictionary containing the gradients\n",
    "  costs: list of all the costs computed during the optimisation (can be used to plot the learning curve).\n",
    "  \"\"\"\n",
    "  costs = []\n",
    "    \n",
    "  for i in range(num_iterations):\n",
    "\n",
    "      # calculate cost and gradients\n",
    "      grads, cost = propagate(X, y, beta, beta_0)\n",
    "      \n",
    "      # retrieve derivatives from grads\n",
    "      dbeta = grads[\"dbeta\"]\n",
    "      dbeta_0 = grads[\"dbeta_0\"]\n",
    "      \n",
    "      # updating procedure\n",
    "      beta = beta - learning_rate * dbeta\n",
    "      beta_0 = beta_0 - learning_rate * dbeta_0\n",
    "      \n",
    "      # record the costs\n",
    "      if i % 100 == 0:\n",
    "          costs.append(cost)\n",
    "      \n",
    "      # print the cost every 100 iterations\n",
    "      if print_cost and i % 100 == 0:\n",
    "          print (\"cost after iteration %i: %f\" %(i, cost))\n",
    "  \n",
    "  # save parameters and gradients in dictionary\n",
    "  params = {\"beta\": beta, \"beta_0\": beta_0}\n",
    "  grads = {\"dbeta\": dbeta, \"dbeta_0\": dbeta_0}\n",
    "  \n",
    "  return params, grads, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-guarantee",
   "metadata": {},
   "source": [
    "Then we make a function to predict labels given the parameters $\\beta$ and a new set X_test.\n",
    "Here we also have the decision threshold as a hyper-parameter, that is the probability boundary at which the class that a data point is assigned to changes.\n",
    "\n",
    "$$\\hat{\\boldsymbol y}_{\\text{log}} = f(\\boldsymbol \\beta^T \\boldsymbol X + \\beta_0) > \\tau \\Rightarrow \\boldsymbol X \\in {1}$$\n",
    "where $\\tau$ is the decision threshold.\n",
    "\n",
    "In this way we transform the regression to a classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "protecting-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that predicts the labels for a given data given the beta parameters\n",
    "def predict(X_test, beta, beta_0, decision_threshold):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X_test: test data of size (d, n)\n",
    "    beta: parameters, a numpy array of size (d, 1)\n",
    "    beta_0: offset, a scalar\n",
    "    decision_threshold: a scalar in [0,1]\n",
    "    \n",
    "    Returns:\n",
    "    y_pred: vector containing all binary predictions (0/1) for the examples in X_test\n",
    "    \"\"\"\n",
    "    n = X_test.shape[1]\n",
    "    y_pred = np.zeros((1,n))\n",
    "    beta = beta.reshape(X_test.shape[0], 1)\n",
    "    \n",
    "    # compute vector y_log predicting the probabilities\n",
    "    y_log = predict_log(X_test, beta, beta_0)\n",
    "    \n",
    "    for i in range(y_log.shape[1]):\n",
    "        \n",
    "        # convert probabilities y_log to actual predictions y_pred\n",
    "        if y_log[0, i] > decision_threshold:\n",
    "            y_pred[0, i] = 1\n",
    "        else:\n",
    "            y_pred[0, i] = 0\n",
    "    \n",
    "    assert(y_pred.shape==(1, n))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-leonard",
   "metadata": {},
   "source": [
    "Finally we make a main function that trains model given the hyperparameters as arguments and returns all the relevant information including the accuracies and the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "electronic-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One function that has all hyperparameters as arguments\n",
    "def model(X_train, y_train, X_test, y_test, \n",
    "          decision_threshold, num_iterations=5000, learning_rate=0.5, print_cost=False):\n",
    "    # initialize parameters with zeros\n",
    "    beta, beta_0 = initialise(X_train.shape[0])\n",
    "    \n",
    "    # gradient descent\n",
    "    parameters, grads, costs = optimise(X_train, y_train, beta, beta_0, \n",
    "                                        num_iterations, learning_rate, print_cost=print_cost)\n",
    "    \n",
    "    # retrieve parameters beta and beta_0 from dictionary \"parameters\"\n",
    "    beta = parameters[\"beta\"]\n",
    "    beta_0 = parameters[\"beta_0\"]\n",
    "    \n",
    "    # predict test and train set examples\n",
    "    y_pred_test = predict(X_test, beta, beta_0, decision_threshold)\n",
    "    y_pred_train = predict(X_train, beta, beta_0, decision_threshold)\n",
    "    \n",
    "    # obtain train/test Errors\n",
    "    train_accuracy = 100 - np.mean(np.abs(y_pred_train - y_train)) * 100\n",
    "    test_accuracy = 100 - np.mean(np.abs(y_pred_test - y_test)) * 100\n",
    "    \n",
    "    # saving all information\n",
    "    d = {\"costs\": costs, \n",
    "         \"y_pred_test\": y_pred_test, \n",
    "         \"y_pred_train\": y_pred_train, \n",
    "         \"beta\": beta, \"beta_0\": beta_0, \n",
    "         \"learning_rate\": learning_rate, \n",
    "         \"num_iterations\": num_iterations,\n",
    "         \"train_acc\": train_accuracy,\n",
    "         \"test_acc\": test_accuracy}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-solomon",
   "metadata": {},
   "source": [
    "In order to perform grid search, we consider 10 evenly spaced values between 0 and 1 as possible values for both the learning rate and the decision threshold, and we make a grid using this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "auburn-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to create a grid given two vectors\n",
    "def make_grid(v1,v2):\n",
    "    grid = np.array(np.meshgrid(v1, v2))\n",
    "    return grid.T.reshape(-1,2)\n",
    "\n",
    "# Create the grid for grid search\n",
    "learning_rate_vec = np.arange(1,11) / 10\n",
    "decision_threshold_vec = np.arange(1,11) / 10\n",
    "grid = make_grid(learning_rate_vec, decision_threshold_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-bouquet",
   "metadata": {},
   "source": [
    "Next we aggregate the X_train and Y_train data to be split into folds for cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "central-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the X and Y data into one array to be used for cross validation\n",
    "train = np.hstack((X_train, Y_train[:, np.newaxis]))\n",
    "\n",
    "# Generate the folds\n",
    "folds = cross_val_split(train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-yacht",
   "metadata": {},
   "source": [
    "Finally we make a function that performs the cross validation and grid search as required, and stores the accuracies in dictionaries that we can access at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "polyphonic-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_evaluate_logistic(folds, grid):\n",
    "    # create dictionaries\n",
    "    train_acc = {1:[], 2:[], 3:[], 4:[], 5:[]}\n",
    "    val_acc = {1:[], 2:[], 3:[], 4:[], 5:[]}\n",
    "\n",
    "    for i in range(len(folds)):\n",
    "      \n",
    "        print('Fold', i+1)\n",
    "        # define the training set (i.e. selecting all folds and deleting the one used for validation)\n",
    "        train_set = np.delete(np.asarray(folds).reshape(len(folds), folds[0].shape[0], folds[0].shape[1]), i, axis=0)\n",
    "        train_folds = train_set.reshape(len(train_set)*train_set[0].shape[0], train_set[0].shape[1])\n",
    "        X_train = train_folds[:,:-1].T\n",
    "        y_train = train_folds[:, -1]\n",
    "        \n",
    "        # define the validation set\n",
    "        val_fold = folds[i]\n",
    "        X_val = val_fold[:,:-1].T\n",
    "        y_val = val_fold[:, -1]\n",
    "    \n",
    "        # train the model and obtain the beta parameters for each combination\n",
    "        # GRID SEARCH\n",
    "        for parameters in grid:            \n",
    "            # train the model\n",
    "            model_dict = model(X_train, y_train, X_val, y_val, decision_threshold=parameters[1], num_iterations=5000, learning_rate=parameters[0])\n",
    "            \n",
    "            # obtain the accuracies and store these in the appropriate dictionaries\n",
    "            train_acc[i+1].append(model_dict[\"train_acc\"])\n",
    "            val_acc[i+1].append(model_dict[\"test_acc\"])\n",
    "    \n",
    "    print(\"Training finished.\")\n",
    "    return train_acc, val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-values",
   "metadata": {},
   "source": [
    "We call the function and obtain the optimal set of hyperparameters by computing the average validation accuracy for each combination over the folds, and finding the combination that results in the maximum:\n",
    "\n",
    "[Note this can take several minutes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "psychological-analyst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Training finished.\n",
      "Optimal Decision Threshold: 0.5\n",
      "Optimal Learning Rate    : 0.4\n"
     ]
    }
   ],
   "source": [
    "train_acc, val_acc = cross_val_evaluate_logistic(folds, grid)\n",
    "\n",
    "# Compute the average validation accuracy over the folds, to get average for each penalty term\n",
    "average_val_acc = np.mean([val_acc[fold] for fold in range(1, 6)], axis = 0)\n",
    "optimal_parameters = grid[np.argmax(average_val_acc)]\n",
    "\n",
    "print(\"Optimal Decision Threshold: \" + str(optimal_parameters[1]))\n",
    "print(\"Optimal Learning Rate    : \" + str(optimal_parameters[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-pierce",
   "metadata": {},
   "source": [
    "We can visualise the grid search over the hyperparameters using a 3d plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "together-snowboard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "# Plot the surface.\n",
    "surf = ax.plot_trisurf(grid[:,0], grid[:,1], average_val_acc, cmap=cm.coolwarm,\n",
    "                       linewidth=0)\n",
    "ax.view_init(15, 220)\n",
    "ax.set_xlabel('Learning Rate')\n",
    "ax.set_ylabel('Decision Threshold')\n",
    "ax.set_zlabel('Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-philadelphia",
   "metadata": {},
   "source": [
    "#### Question 2.1.2\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-seattle",
   "metadata": {},
   "source": [
    "Finally we retrain the model on the whole dataset using the optimal hyperparameters and compare the mean accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "short-advisory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 74.375 %\n",
      "Test set accuracy    : 74.0 %\n"
     ]
    }
   ],
   "source": [
    "# Retrain the model using the optimal paramaters\n",
    "d = model(X_train.T, Y_train, X_test.T, Y_test, decision_threshold=optimal_parameters[1],\n",
    "          num_iterations=5000, learning_rate=optimal_parameters[0])\n",
    "\n",
    "# Mean Accuracies\n",
    "print(\"Training set accuracy: {} %\".format(d[\"train_acc\"]))\n",
    "print(\"Test set accuracy    : {} %\".format(d[\"test_acc\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-hands",
   "metadata": {},
   "source": [
    "We observe that the mean accuracies of our optimal model are fairly close to eachother and well above 50%, which suggests that overfitting has not occured. \n",
    "However clearly there is still room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-program",
   "metadata": {},
   "source": [
    "### 2.2 Random Forest\n",
    "***\n",
    "\n",
    "#### Question 2.2.1\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-supply",
   "metadata": {},
   "source": [
    "As decision trees are the building blocks of random forests, we start by creating an appropriate decision tree model for the data.\n",
    "\n",
    "Once again we check the first few rows of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "controversial-sydney",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.16176470588235292</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.36315615714757354</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33333333333333326</td>\n",
       "      <td>0.33333333333333326</td>\n",
       "      <td>0.26785714285714285</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4705882352941176</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8587542643336633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33333333333333326</td>\n",
       "      <td>0.6666666666666667</td>\n",
       "      <td>0.6666666666666665</td>\n",
       "      <td>0.4285714285714285</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1176470588235294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1380543633762518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33333333333333326</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33333333333333326</td>\n",
       "      <td>0.26785714285714285</td>\n",
       "      <td>0.6666666666666665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4705882352941176</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.17585561791570375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33333333333333326</td>\n",
       "      <td>0.6666666666666665</td>\n",
       "      <td>0.41071428571428575</td>\n",
       "      <td>0.6666666666666665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6470588235294117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2396280400572246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6666666666666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0892857142857143</td>\n",
       "      <td>0.6666666666666665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0    1                   2    3   4                   5   \\\n",
       "0 0.16176470588235292 0.25 0.36315615714757354 0.25 0.0                 0.0   \n",
       "1  0.4705882352941176  0.5  0.8587542643336633  0.0 0.0 0.33333333333333326   \n",
       "2  0.1176470588235294  0.0  0.1380543633762518  0.0 1.0 0.33333333333333326   \n",
       "3  0.4705882352941176  0.5 0.17585561791570375  0.0 1.0                 1.0   \n",
       "4  0.6470588235294117  0.0  0.2396280400572246  0.0 1.0  0.6666666666666667   \n",
       "\n",
       "                   6                   7                   8   \\\n",
       "0 0.33333333333333326 0.33333333333333326 0.26785714285714285   \n",
       "1  0.6666666666666667  0.6666666666666665  0.4285714285714285   \n",
       "2                 1.0 0.33333333333333326 0.26785714285714285   \n",
       "3 0.33333333333333326  0.6666666666666665 0.41071428571428575   \n",
       "4                 1.0                 1.0  0.0892857142857143   \n",
       "\n",
       "                  9   10  \n",
       "0                1.0 1.0  \n",
       "1                1.0 0.0  \n",
       "2 0.6666666666666665 0.0  \n",
       "3 0.6666666666666665 0.0  \n",
       "4 0.6666666666666665 0.0  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-brazil",
   "metadata": {},
   "source": [
    "We observe that the data consists of continuous variables, so we start by adapting the decision tree from the coding task which was constructed for discrete data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-certification",
   "metadata": {},
   "source": [
    "Also instead of using the gini index, we will use the cross entropy as the information criterion to measure the quality of the classification for a given split.\n",
    "\n",
    "The formula I am using for the entropy is:\n",
    "$$ - \\sum_{k=1}^{K} \\hat{p}_{mk} \\log(\\hat{p}_{mk}) $$ \n",
    "where $\\hat{p}_{mk}$ is the porportion of class k observations in node m.\n",
    "\n",
    "The source of this formula is from Page 309, Chapter 9.2 of the book \"The Elements of Statistical Learning\" - Trevor Hastie, Robert Tibshirani, Jerome Friedman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-helicopter",
   "metadata": {},
   "source": [
    "We define a function to calculate the cross entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "acting-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y, sample_weights=None):\n",
    "    \"\"\" \n",
    "    Calculate the cross_entropy for labels.\n",
    "    Arguments:\n",
    "        y: vector of training labels, of shape (N,).\n",
    "        sample_weights: weights for each samples, of shape (N,).\n",
    "    Returns:\n",
    "        (float): the cross entropy for y.\n",
    "    \"\"\"\n",
    "    if sample_weights is None:\n",
    "        sample_weights = np.ones(y.shape[0]) / y.shape[0]\n",
    "    \n",
    "    ce = 0\n",
    "    num = y.shape[0]  # number of labels\n",
    "    label_counts = {}  # caculate different labels in y，and store in label_counts\n",
    "    for i in range(num):\n",
    "        if y[i] not in label_counts.keys():\n",
    "            label_counts[y[i]] = 0\n",
    "        label_counts[y[i]] += sample_weights[i]\n",
    "    \n",
    "    for key in label_counts:\n",
    "        prob = float(label_counts[key]) / float(np.sum(sample_weights))\n",
    "        ce -= prob * np.log(prob)\n",
    "    \n",
    "    return ce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-optimization",
   "metadata": {},
   "source": [
    "Next we have the functions that split the data into two regions given a column and a value, and also a function to calculate the total cross entropy for every feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "colonial-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y, column, value, sample_weights=None):\n",
    "    # create two regions R1 and R2\n",
    "    R1 = []\n",
    "    R2 = []\n",
    "    featVec = X[:, column]\n",
    "    \n",
    "    # selecting all columns of X except the \"column\" we are splitting on\n",
    "    X = X[:,[i for i in range(X.shape[1]) if i!=column]]  \n",
    "    \n",
    "    for i in range(len(featVec)):\n",
    "        # we use <= instead of < as we are dealing with continuous data\n",
    "        if featVec[i] <= value:\n",
    "            R1.append(i)\n",
    "        else:\n",
    "            R2.append(i)   \n",
    "            \n",
    "    # create the split regions in terms of X and y variables\n",
    "    X1 = X[R1,:]\n",
    "    y1 = y[R1]\n",
    "    X2 = X[R2,:]\n",
    "    y2 = y[R2]\n",
    "    \n",
    "    # return the list of splits\n",
    "    if sample_weights is None:\n",
    "        return [(X1, y1), (X2, y2)]\n",
    "    else:\n",
    "        return [(X1, y1, sample_weights[R1]) , (X2, y2, sample_weights[R2])]\n",
    "\n",
    "def cross_entropy_calculate(X, y, column, value, sample_weights=None):\n",
    "    \n",
    "    if sample_weights is None:\n",
    "        sample_weights = np.ones(y.shape[0]) / y.shape[0]\n",
    "    \n",
    "    information_gain = 0\n",
    "    new_cost = 0.0\n",
    "    \n",
    "    old_cost = cross_entropy(y, sample_weights)\n",
    "    \n",
    "    # split the values of i-th feature and calculate the cost of the split\n",
    "    for sub_X, sub_y, sub_sample_weights in split_dataset(X, y, column, value, sample_weights):\n",
    "        prob = np.sum(sub_sample_weights) / float(np.sum(sample_weights))\n",
    "        \n",
    "        # New cost (cross entropy multiplied by a weighted prob depending on the sample weights)\n",
    "        new_cost += prob * cross_entropy(sub_y, sub_sample_weights)\n",
    "  \n",
    "    # information gain\n",
    "    information_gain = old_cost - new_cost \n",
    "\n",
    "    return information_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-saskatchewan",
   "metadata": {},
   "source": [
    "Then we create a function to choose the best feature to split on according to the information gain for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "appreciated-discrimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_feature(X, y, max_features, sample_weights=None):\n",
    "    \n",
    "    # create sample_weights if not there already\n",
    "    if sample_weights is None:\n",
    "        sample_weights = np.ones(y.shape[0]) / y.shape[0]\n",
    "        \n",
    "    n_features = X.shape[1]\n",
    "    \n",
    "    # ensure the number of features chosen are not more than max_features\n",
    "    if n_features > max_features:\n",
    "        n_features = max_features\n",
    "    \n",
    "    # initialise variables\n",
    "    best_split=None\n",
    "    best_gain_cost = 0.0\n",
    "    \n",
    "    # shuffle the indices so we don't choose the first n features each time\n",
    "    indices = np.arange(X.shape[1])\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    # loop through the features\n",
    "    for feat_index in indices[:max_features]:\n",
    "        \n",
    "        # find the unique values for a given feature and loop through these\n",
    "        unique_values = np.unique(X[:, feat_index])\n",
    "        for val in unique_values:\n",
    "            # for each value calculate the cross entropy\n",
    "            info_gain_cost = cross_entropy_calculate(X, y, feat_index, val, sample_weights)\n",
    "            # check if this is better than the best split so far and update if it is\n",
    "            if info_gain_cost > best_gain_cost:\n",
    "                best_gain_cost = info_gain_cost\n",
    "                best_split = (feat_index, val)     \n",
    "    \n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-opportunity",
   "metadata": {},
   "source": [
    "Then a function to return the majority label of a vector of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "copyrighted-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(y, sample_weights=None):\n",
    "    \"\"\"\n",
    "    Return the label which appears the most in y.\n",
    "    Args:\n",
    "      y: vector of training labels, of shape (N,).\n",
    "      sample_weights: weights for each samples, of shape (N,).\n",
    "    Returns:\n",
    "      (int): the majority label\n",
    "    \"\"\"\n",
    "    if sample_weights is None:\n",
    "      sample_weights = np.ones(y.shape[0]) / y.shape[0]\n",
    "\n",
    "    majority_label = y[0]\n",
    "\n",
    "    dict_num = {}\n",
    "    for i in range(y.shape[0]):\n",
    "      if y[i] not in dict_num.keys():\n",
    "          dict_num[y[i]] = sample_weights[i]\n",
    "      else:\n",
    "          dict_num[y[i]] += sample_weights[i]\n",
    "\n",
    "    majority_label = max(dict_num, key=dict_num.get)\n",
    "    return majority_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-seating",
   "metadata": {},
   "source": [
    "Finally we have the function to build the optimal decision tree by calling all the functions above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "convertible-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(X, y, feature_names, max_features, max_depth, current_depth, sample_weights=None, min_samples_leaf=2):\n",
    "    \"\"\"Build the decision tree according to the data.\n",
    "    X and y arguments:\n",
    "        X: (np.array) training features, of shape (N, D).\n",
    "        y: (np.array) vector of training labels, of shape (N,).\n",
    "    Returns:\n",
    "        (dict): a dict denoting the decision tree. \n",
    "        <tree> ::= node:'leaf' label:<iris-categ>\n",
    "                |  node:'split' feature-name:<col-name> value:<num> leaf:<tree> right:<tree>  \n",
    "    \"\"\"\n",
    "    mytree = dict()\n",
    "    \n",
    "    # include a clause for the cases where (i) no feature, (ii) all lables are the same, \n",
    "    # (iii) depth exceed, or (iv) X is too small, or (v) X consists of exactly the same features\n",
    "    if (len(feature_names)==0 or len(np.unique(y))==1 or \n",
    "        current_depth>=max_depth or len(X)<=min_samples_leaf or len(np.unique(X, axis = 0))) == 1:\n",
    "        \n",
    "        mytree = {'node':'leaf' ,  'label': majority_vote(y, sample_weights)}\n",
    "        return mytree\n",
    "    \n",
    "    best_split = choose_best_feature(X, y, max_features, sample_weights)    \n",
    "    \n",
    "    # case where there is no best split\n",
    "    if best_split == None:\n",
    "        mytree = {'node':'leaf' ,  'label': majority_vote(y, sample_weights)}\n",
    "        return mytree\n",
    "    \n",
    "    else:  \n",
    "        # retrieve the feature and value of the best_split\n",
    "        best_feature_idx, value = best_split\n",
    "        best_feature_name = feature_names[best_feature_idx]\n",
    "        \n",
    "        # remove the feature name used for this split from the list of names\n",
    "        feature_names = feature_names[:]\n",
    "        feature_names.remove(best_feature_name)\n",
    "        \n",
    "        # split the data according to the best split\n",
    "        splits = split_dataset(X, y, best_feature_idx, value, sample_weights)\n",
    "        \n",
    "        # create the tree for this specific split\n",
    "        mytree = {'node':'split', 'feature_name':best_feature_name, 'value':value}\n",
    "        \n",
    "        # obtain the information for the two regions of the split\n",
    "        sub_X_left, sub_Y_left, sub_sample_weight_left = splits[0]\n",
    "        sub_X_right, sub_Y_right, sub_sample_weight_right = splits[1]\n",
    "        \n",
    "        # expand the tree by recursively calling the same function to making further splits for each new region\n",
    "        mytree['Left'] = build_tree(sub_X_left, sub_Y_left, feature_names, max_features, max_depth, current_depth+1, sub_sample_weight_left) \n",
    "        mytree['Right'] = build_tree(sub_X_right, sub_Y_right, feature_names, max_features, max_depth, current_depth+1, sub_sample_weight_right) \n",
    "          \n",
    "        return mytree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-meeting",
   "metadata": {},
   "source": [
    "We also have a overall function to train the tree with the hyperparameters as arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "criminal-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree(X, y, max_features, max_depth, sample_weights=None):\n",
    "    \"\"\"\n",
    "    Build the decision tree according to the training data.\n",
    "    \"\"\"\n",
    "    if sample_weights is None:\n",
    "        # if the sample weights is not provided, we assume the samples have uniform weights\n",
    "        sample_weights = np.ones(X.shape[0]) / X.shape[0]\n",
    "    else:\n",
    "        sample_weights = np.array(sample_weights) / np.sum(sample_weights)\n",
    "    \n",
    "    feature_names = X.columns.tolist()\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    tree = build_tree(X, y, feature_names, max_features, max_depth, current_depth=1, sample_weights=sample_weights)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-industry",
   "metadata": {},
   "source": [
    "Then we have two further functions: \"classify\" to classify a data point given a tree and the point, and \"predict\" to call this function for for every data point from a set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "proper-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, x):\n",
    "    \"\"\"\n",
    "    Classify a single sample with the fitted decision tree.\n",
    "    Args:\n",
    "        x: ((pd.Dataframe) a single sample features, of shape (D,).\n",
    "    Returns:\n",
    "        (int): predicted testing sample label.\n",
    "    \"\"\"\n",
    "    # check if there is no further split\n",
    "    if tree['node'] == 'leaf':\n",
    "        return tree['label']\n",
    "        # if there is a further split, check which region the data point belongs to\n",
    "    else:\n",
    "        feat_name = tree['feature_name']\n",
    "        val = x.loc[feat_name]\n",
    "        # go the the appropriate region and recursively call the classify function\n",
    "        if (val <= tree['value']):\n",
    "            return classify(tree['Left'],x)\n",
    "        else:\n",
    "            return classify(tree['Right'],x)\n",
    "\n",
    "def predict(tree, X):\n",
    "    \"\"\"\n",
    "    Predict classification results for X.\n",
    "    Args:\n",
    "        X: (pd.Dataframe) testing sample features, of shape (N, D).\n",
    "    Returns:\n",
    "        (np.array): predicted testing sample labels, of shape (N,).\n",
    "    \"\"\"\n",
    "    if len(X.shape)==1:\n",
    "        return classify(tree, X)\n",
    "    else:\n",
    "        results=[]\n",
    "        for i in range(X.shape[0]):\n",
    "            results.append(classify(tree, X.iloc[i, :]))\n",
    "        return np.array(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-senior",
   "metadata": {},
   "source": [
    "We also create a score function to measure the accuracy of our predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "imposed-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(tree, X_test, y_test):\n",
    "    y_pred = predict(tree, X_test)\n",
    "    return np.float(sum(y_pred==y_test)) / float(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-competition",
   "metadata": {},
   "source": [
    "Now that we have our code to create decision trees and get predictions using them, we move on to random forests.\n",
    "The first step of random forests is bootstrapping. That is, producing samples of size $N'$ from the training data (where $N' < N$ and $N$ is the size of the training data). These samples are with replacement.\n",
    "\n",
    "The following function performs bootstrapping and has N_trees as the argument for the number of samples. The bootstrapped sets are stored in dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fourth-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bootstrapped dataset given a data frame\n",
    "def bootstrap(df_data, N_trees):\n",
    "    # dictionary to store each sample\n",
    "    boot_data = dict()\n",
    "    \n",
    "    # random sampling with replacement\n",
    "    for i in range(N_trees):\n",
    "        boot_data[i] = df_data.sample(n = int(len(X_train) * 9/10), replace = True)\n",
    "        \n",
    "    return boot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-knight",
   "metadata": {},
   "source": [
    "The next step of random forests is to get an ensemble of decision trees, one for each sample of the bootsrapped dataset. This is done in the function below, and the trees are stored and returned in a dictionary \"boot_tree\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "expensive-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randforest(df_X_y, N_trees, max_features, max_depth, sample_weights=None):\n",
    "    \n",
    "    # bootstrap the data and create samples\n",
    "    boot_data = bootstrap(df_X_y, N_trees)\n",
    "        \n",
    "    # create a dictionary to store each tree\n",
    "    boot_tree = {}\n",
    "    \n",
    "    # for each sample of the data create a decision tree\n",
    "    for i in range(N_trees):\n",
    "        # split the aggregated X and y into separate arrays again\n",
    "        boot_df_X_y = boot_data[i]\n",
    "        boot_df_X = boot_df_X_y[boot_df_X_y.columns[:-1]]\n",
    "        boot_df_y = boot_df_X_y[boot_df_X_y.columns[-1]]\n",
    "\n",
    "        boot_tree[i] = train_decision_tree(boot_df_X, boot_df_y, max_features, max_depth)\n",
    "    \n",
    "    return boot_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-beverage",
   "metadata": {},
   "source": [
    "The next step is to aggregate the ensemble of models to create a single prediction for each data point.\n",
    "Here we implement this for a single data point in the function \"classify_random_forest\" by hard voting which takes the majority of the class labels.\n",
    "\n",
    "The \"predict_random_forest\" function repeats this for each data point in a given set using a given ensemble of trees, and a vector of predicted values is returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "intensive-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_random_forest(boot_tree, x):\n",
    "    \"\"\"\n",
    "    Classify a single sample with the fitted decision tree.\n",
    "    Returns:\n",
    "        (int): predicted testing sample label.\n",
    "    \"\"\"\n",
    "    # create a list of values predicted by the tree\n",
    "    tree_preds = []\n",
    "    \n",
    "    for i in range(len(boot_tree)):\n",
    "        tree_preds.append(classify(boot_tree[i], x))\n",
    "    \n",
    "    # find frequency of each value\n",
    "    freq_counter = Counter(tree_preds)\n",
    "    freq_dict = dict(freq_counter)\n",
    "    \n",
    "    max_freq = max(list(freq_counter.values()))\n",
    "    modal_values = [num for num, freq in freq_dict.items() if freq == max_freq]\n",
    "    # in case there are multiple modal values, randomly choose from the list\n",
    "    label = modal_values[np.random.randint(0, len(modal_values))]\n",
    "    \n",
    "    return label\n",
    "\n",
    "def predict_random_forest(boot_tree, X):\n",
    "    \"\"\"\n",
    "    Predict classification results for X.\n",
    "    \"\"\"\n",
    "    if len(X.shape)==1:\n",
    "        return classify_random_forest(boot_tree, X)\n",
    "    else:\n",
    "        results=[]\n",
    "        for i in range(X.shape[0]):\n",
    "            results.append(classify_random_forest(boot_tree, X.iloc[i, :]))\n",
    "        return np.array(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-christianity",
   "metadata": {},
   "source": [
    "As with the decision tree, we have a score function to measure the accuracy of our predictions for a particular random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "industrial-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_random_forest(boot_tree, X_test, y_test):\n",
    "    y_pred = predict_random_forest(boot_tree, X_test)\n",
    "    return np.float(sum(y_pred==y_test)) / float(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-copper",
   "metadata": {},
   "source": [
    "In order to perform cross validation, we create a function that has the folds and the three hyperparameters we are interest in (N_trees, max_features, max_depth) as arguments and returns the training and validation accuracies for each fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "blessed-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_evaluate_random_forest(folds, N_trees, max_features, max_depth):\n",
    "    # create dictionaries\n",
    "    train_acc = {1:[], 2:[], 3:[], 4:[], 5:[]}\n",
    "    val_acc = {1:[], 2:[], 3:[], 4:[], 5:[]}\n",
    "    \n",
    "    for i in range(len(folds)):\n",
    "        \n",
    "        # print('Fold', i+1)\n",
    "        # define the training set (i.e. selecting all folds and deleting the one used for validation)\n",
    "        train_set = np.delete(np.asarray(folds).reshape(len(folds), folds[0].shape[0], folds[0].shape[1]), i, axis=0)\n",
    "        train_folds = train_set.reshape(len(train_set)*train_set[0].shape[0], train_set[0].shape[1])\n",
    "        X_train = train_folds[:,:-1]\n",
    "        y_train = train_folds[:, -1]\n",
    "        \n",
    "        # define the validation set\n",
    "        val_fold = folds[i]\n",
    "        X_val = val_fold[:,:-1]\n",
    "        y_val = val_fold[:, -1]\n",
    "    \n",
    "        # convert whole training set, X_train and X_val into panda data frames as required\n",
    "        df_train = pd.DataFrame(train_folds)\n",
    "        df_X_train = pd.DataFrame(X_train)\n",
    "        df_X_val = pd.DataFrame(X_val)\n",
    "        \n",
    "        # train the random forest and obtain the trees\n",
    "        boot_tree = randforest(df_train, N_trees, max_features, max_depth, sample_weights=None)\n",
    "        \n",
    "        # obtain the accuracies and store in the appropriate dictionaries\n",
    "        train_accuracy = score_random_forest(boot_tree, df_X_train, y_train)\n",
    "        val_accuracy = score_random_forest(boot_tree, df_X_val, y_val)\n",
    "        \n",
    "        train_acc[i+1].append(train_accuracy)\n",
    "        val_acc[i+1].append(val_accuracy)\n",
    "        \n",
    "    return train_acc, val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-poultry",
   "metadata": {},
   "source": [
    "In order to scan the parameters we create vector of possible values for each hyperparameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "formed-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectors of hyperparameters\n",
    "N_trees_vec = np.array([4, 8, 12, 16, 20])\n",
    "max_features_vec = np.array([2, 4, 6, 8, 10])\n",
    "max_depth_vec = np.array([2, 4, 6, 8, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-walter",
   "metadata": {},
   "source": [
    "I chose to restrict the number of values I scan though as this process proved to be very computationally expensive for large vectors, in some cases taking up to an hour for vectors of 10 values.\n",
    "\n",
    "Further I restricted the range of the parameter for the maximum number of descriptors at each split (max_features) to between 2 and 10 as it was stated that in lectures that the guideline or this number is approximately $\\frac{p}{3}$ (where $p$ is the number f predictors), and here we have that p = 11.\n",
    "\n",
    "Similarly I chose to restrict the maximum depth (max_depth) of the trees as there are only 11 descriptors in total, and overfitting could occur if the depth is too large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-cedar",
   "metadata": {},
   "source": [
    "Further, a grid search over every combination of the hyperparameters proved to be unnecessarily computationally expensive.\n",
    "So I decided to fix the number of decision trees and perform a grid search over max_features and max_depth first:\n",
    "\n",
    "[Note this can take around 10 minutes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "valid-street",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Loop: 1/5\n",
      "Outer Loop: 2/5\n",
      "Outer Loop: 3/5\n",
      "Outer Loop: 4/5\n",
      "Outer Loop: 5/5\n"
     ]
    }
   ],
   "source": [
    "# Create matrices to store accuracies\n",
    "train_acc_matrix = np.zeros((5,5))\n",
    "val_acc_matrix = np.zeros((5,5))\n",
    "\n",
    "# Grid Search over max_features and max_depth keeping N_trees fixed at 5\n",
    "for j, max_feat in enumerate(max_features_vec):\n",
    "    print(\"Outer Loop: \" + str(j+1)+ \"/5\")\n",
    "    for k, max_depth in enumerate(max_depth_vec):\n",
    "        train_accuracy, val_accuracy = cross_val_evaluate_random_forest(folds, 5, max_feat, max_depth)\n",
    "        mean_train_accuracy = np.mean([train_accuracy[i][0] for i in range(1,6)])\n",
    "        mean_val_accuracy = np.mean([val_accuracy[i][0] for i in range(1,6)])\n",
    "        \n",
    "        train_acc_matrix[j,k] = mean_train_accuracy\n",
    "        val_acc_matrix[j,k] = mean_val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-fight",
   "metadata": {},
   "source": [
    "From this we can find the optimal pair of these hyperparamaters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "searching-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_indices = np.where(val_acc_matrix == val_acc_matrix.max())\n",
    "optimal_max_features = max_features_vec[optimal_indices[0][0]]\n",
    "optimal_max_depth = max_depth_vec[optimal_indices[1][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-springfield",
   "metadata": {},
   "source": [
    "Next, using these optimal values, I varied the number of trees using the N_trees vector to find the optimal number of decision trees:\n",
    "\n",
    "[Note this can take a couple of minutes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "specified-works",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop: 1/5\n",
      "Loop: 2/5\n",
      "Loop: 3/5\n",
      "Loop: 4/5\n",
      "Loop: 5/5\n"
     ]
    }
   ],
   "source": [
    "# Create matrices to store accuracies\n",
    "train_acc_matrix = np.zeros(5)\n",
    "val_acc_matrix = np.zeros(5)\n",
    "\n",
    "for i, N_trees, in enumerate(N_trees_vec):\n",
    "    print(\"Loop: \" + str(i+1)+ \"/5\")\n",
    "    train_accuracy, val_accuracy = cross_val_evaluate_random_forest(folds, N_trees, optimal_max_features, optimal_max_depth)\n",
    "    mean_train_accuracy = np.mean([train_accuracy[k][0] for k in range(1,6)])\n",
    "    mean_val_accuracy = np.mean([val_accuracy[k][0] for k in range(1,6)])\n",
    "    \n",
    "    train_acc_matrix[i] = mean_train_accuracy\n",
    "    val_acc_matrix[i] = mean_val_accuracy\n",
    "    \n",
    "optimal_index = np.where(val_acc_matrix == val_acc_matrix.max())\n",
    "optimal_N_trees = N_trees_vec[optimal_index[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-reach",
   "metadata": {},
   "source": [
    "These optimal hyperparameters are summarised below:\n",
    "\n",
    "[In case the code takes a long time to execute, for reference the optimal parameters for this seed were: (16, 6, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "focused-drama",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Decision Trees</th>\n",
       "      <th>Depth of Trees</th>\n",
       "      <th>Maximum Number of Descriptors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Optimal Value</th>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Number of Decision Trees  Depth of Trees  \\\n",
       "Optimal Value                        16               6   \n",
       "\n",
       "               Maximum Number of Descriptors  \n",
       "Optimal Value                              2  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_forest_hyper = np.array([[optimal_N_trees], [optimal_max_depth], [optimal_max_features]])\n",
    "rand_forest_hyper_df = pd.DataFrame(rand_forest_hyper.T, \n",
    "                                    columns = [\"Number of Decision Trees\", \n",
    "                                               \"Depth of Trees\", \n",
    "                                               \"Maximum Number of Descriptors\"], \n",
    "                                    index = [\"Optimal Value\"])\n",
    "rand_forest_hyper_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-potato",
   "metadata": {},
   "source": [
    "#### Question 2.2.2\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-discount",
   "metadata": {},
   "source": [
    "Finally we train the random forest model using the set of optimal hyperparameters and compute the accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "isolated-acquisition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - In-Sample accuracy     : 0.76875\n",
      "Random Forest - Out-of-Sample accuracy : 0.7\n"
     ]
    }
   ],
   "source": [
    "boot_tree = randforest(train_data, optimal_N_trees, optimal_max_features, optimal_max_depth, sample_weights=None)\n",
    "print('Random Forest - In-Sample accuracy     :', score_random_forest(boot_tree, df_X_train, df_Y_train))\n",
    "print('Random Forest - Out-of-Sample accuracy :', score_random_forest(boot_tree, df_X_test, df_Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-yeast",
   "metadata": {},
   "source": [
    "Next using the predictions, we create a confusion matrix to see better visualise the accuracy of our predictions:\n",
    "\n",
    "[ Note the code used for constructing the confusion matrix is adapted from: https://datatofish.com/confusion-matrix-python/ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "preliminary-african",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# obtain the predictions\n",
    "Y_train_preds = predict_random_forest(boot_tree, df_X_train)\n",
    "Y_test_preds = predict_random_forest(boot_tree, df_X_test)\n",
    "\n",
    "# construct the confusion matrices\n",
    "df_data_train = pd.DataFrame({'y_Actual [Train]': Y_train, 'y_Predicted [Train]': Y_train_preds})\n",
    "df_data_test = pd.DataFrame({'y_Actual [Test]': Y_test, 'y_Predicted [Test]': Y_test_preds})\n",
    "\n",
    "confusion_matrix_train = pd.crosstab(df_data_train['y_Actual [Train]'], df_data_train['y_Predicted [Train]'], \n",
    "                                     rownames=['Actual'], colnames=['Predicted'])\n",
    "confusion_matrix_test = pd.crosstab(df_data_test['y_Actual [Test]'], df_data_test['y_Predicted [Test]'], \n",
    "                                    rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "# plot the matrices\n",
    "ax = sns.heatmap(confusion_matrix_train, annot=True, fmt='g')\n",
    "plt.title(\"Confusion Matrix for Training Data\")\n",
    "plt.show()\n",
    "\n",
    "sns.heatmap(confusion_matrix_test, annot=True, fmt='g')\n",
    "plt.title(\"Confusion Matrix for Test Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-scanner",
   "metadata": {},
   "source": [
    "We can note that for both datasets, that for data points where the actual value is 1, the model correctly predicts this label for the vast majority (for example 132 / 137 times for the test data). Thus the model seems to have a high true postive rate.\n",
    "\n",
    "However for points where the actual value is 0, the model incorrectly predicts the label 1 more often than not.\n",
    "This is suggests that the true negative rate is not very good (8 / 63 for the test data).\n",
    "\n",
    "The fact that the accuracies shown above are fairly consistent in and out-of-sample suggests that overfitting might not be occuring. However we do see that in these data sets the model is far more likely to predict the label 1 than 0 (which is representative of the datasets), but we cannot be sure that the model will still be appropriate if we get a completely new dataset with a different distribution of 1s and 0s.\n",
    "\n",
    "So we see that the random forest model performs classification to a fairly high degree of accuracy, but improvements can still be made by further tuning the hyperparameters more precisely, however these will always come with the added cost of computational time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-capital",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
