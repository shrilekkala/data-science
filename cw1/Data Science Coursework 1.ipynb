{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "popular-invention",
   "metadata": {},
   "source": [
    "# Data Science: Coursework 1\n",
    "\n",
    "### Shri Lekkala\n",
    "### CID: 01499487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "amazing-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules used throughout the coursework\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "np.random.seed(1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-customer",
   "metadata": {},
   "source": [
    "## Task 1: Regression\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-psychiatry",
   "metadata": {},
   "source": [
    "### 1.1 Linear Regression\n",
    "***\n",
    "\n",
    "#### Question 1.1.1\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-angola",
   "metadata": {},
   "source": [
    "First the training and the test data are imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "floating-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training and test sets\n",
    "test_data = pd.read_csv('./regression_test.csv', header=None)\n",
    "train_data = pd.read_csv('./regression_train.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-mobility",
   "metadata": {},
   "source": [
    "We can check the structure of the dataset as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "saved-touch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.413447</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>0.115735</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>0.984960</td>\n",
       "      <td>0.797449</td>\n",
       "      <td>-0.773684</td>\n",
       "      <td>0.985161</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.983048</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>1.176469</td>\n",
       "      <td>-0.487723</td>\n",
       "      <td>-0.773598</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.412788</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.034027</td>\n",
       "      <td>-1.034035</td>\n",
       "      <td>-0.386091</td>\n",
       "      <td>0.819700</td>\n",
       "      <td>0.207144</td>\n",
       "      <td>-0.418203</td>\n",
       "      <td>0.819617</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-0.857929</td>\n",
       "      <td>0.379323</td>\n",
       "      <td>-0.803625</td>\n",
       "      <td>-0.386091</td>\n",
       "      <td>-0.857939</td>\n",
       "      <td>-0.487723</td>\n",
       "      <td>-0.418305</td>\n",
       "      <td>29.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.387983</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.211099</td>\n",
       "      <td>-0.211084</td>\n",
       "      <td>0.261784</td>\n",
       "      <td>-0.510932</td>\n",
       "      <td>-0.923682</td>\n",
       "      <td>-0.671859</td>\n",
       "      <td>-0.511320</td>\n",
       "      <td>-0.102376</td>\n",
       "      <td>0.344213</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>0.131334</td>\n",
       "      <td>0.261784</td>\n",
       "      <td>0.344218</td>\n",
       "      <td>-0.487727</td>\n",
       "      <td>-0.671863</td>\n",
       "      <td>24.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.347952</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.720322</td>\n",
       "      <td>-0.720323</td>\n",
       "      <td>-0.412006</td>\n",
       "      <td>0.846768</td>\n",
       "      <td>0.324494</td>\n",
       "      <td>-0.248591</td>\n",
       "      <td>0.846699</td>\n",
       "      <td>-0.601276</td>\n",
       "      <td>-0.488039</td>\n",
       "      <td>0.369674</td>\n",
       "      <td>-0.381702</td>\n",
       "      <td>-0.412006</td>\n",
       "      <td>-0.488023</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.248524</td>\n",
       "      <td>27.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.330562</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.437258</td>\n",
       "      <td>-0.437249</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.299699</td>\n",
       "      <td>0.918355</td>\n",
       "      <td>0.313581</td>\n",
       "      <td>0.299802</td>\n",
       "      <td>-0.601276</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.342811</td>\n",
       "      <td>0.020597</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>1.176460</td>\n",
       "      <td>-0.487724</td>\n",
       "      <td>0.313542</td>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4         5         6         7   \\\n",
       "0  1.0 -0.413447 -0.487722  0.115738  0.115735  0.158124  0.984960  0.797449   \n",
       "1  1.0 -0.412788 -0.487722 -1.034027 -1.034035 -0.386091  0.819700  0.207144   \n",
       "2  1.0 -0.387983 -0.487722 -0.211099 -0.211084  0.261784 -0.510932 -0.923682   \n",
       "3  1.0 -0.347952 -0.487722 -0.720322 -0.720323 -0.412006  0.846768  0.324494   \n",
       "4  1.0 -0.330562 -0.487722 -0.437258 -0.437249 -0.144217  0.299699  0.918355   \n",
       "\n",
       "         8         9         10        11        12        13        14  \\\n",
       "0 -0.773684  0.985161 -0.803212  1.176466  0.441052 -0.983048  0.158124   \n",
       "1 -0.418203  0.819617 -0.666608 -0.857929  0.379323 -0.803625 -0.386091   \n",
       "2 -0.671859 -0.511320 -0.102376  0.344213  0.441052  0.131334  0.261784   \n",
       "3 -0.248591  0.846699 -0.601276 -0.488039  0.369674 -0.381702 -0.412006   \n",
       "4  0.313581  0.299802 -0.601276  1.176466  0.342811  0.020597 -0.144217   \n",
       "\n",
       "         15        16        17    18  \n",
       "0  1.176469 -0.487723 -0.773598  23.9  \n",
       "1 -0.857939 -0.487723 -0.418305  29.9  \n",
       "2  0.344218 -0.487727 -0.671863  24.5  \n",
       "3 -0.488023 -0.487722 -0.248524  27.5  \n",
       "4  1.176460 -0.487724  0.313542  18.4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-indiana",
   "metadata": {},
   "source": [
    "Firstly we note that there is already a column of ones for the intercept term in linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-detroit",
   "metadata": {},
   "source": [
    "Usually, we make a decision on whether and how to standardise the data here.\n",
    "However by checking the full data (both training and test together), we see that it is already standardised:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "greek-bookmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -0.  0. -0.  0.  0. -0. -0.  0. -0. -0. -0.  0. -0.  0. -0. -0.  0.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# NB our data is already standardised\n",
    "full_data = pd.concat([test_data, train_data])\n",
    "full_X = np.array(full_data.iloc[:,:-1])\n",
    "print(np.mean(full_X, 0).round(decimals=3))\n",
    "print(np.std(full_X, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-session",
   "metadata": {},
   "source": [
    "Thus, except in the case where the column is all ones, the mean of each column is 0 and the standard deviation is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-parallel",
   "metadata": {},
   "source": [
    "Next we separate the data sets in terms of the X and the Y datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fundamental-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train_data.iloc[:,:-1])\n",
    "Y_train = np.array(train_data.iloc()[:,-1])\n",
    "\n",
    "X_test = np.array(test_data.iloc[:,:-1])\n",
    "Y_test = np.array(test_data.iloc()[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-canadian",
   "metadata": {},
   "source": [
    "As we have explored maximum likelihood estimation in lectures, I will apply the same method for this regression problem.\n",
    "\n",
    "In particular we wish to obtain the parameters  $\\boldsymbol\\beta^{\\mathrm{ML}}$ that maximize the likelihood\n",
    "$$\n",
    "p(\\mathcal Y | \\mathcal X, \\boldsymbol\\beta) = \\prod_{n=1}^N p(y_n | \\boldsymbol x_n, \\boldsymbol\\beta)\\,.\n",
    "$$\n",
    "\n",
    "And once we have that we can can compute the maximum likelihood estimate using the formula:\n",
    "$$\n",
    "\\boldsymbol\\beta^{\\text{ML}} = (\\boldsymbol X^T\\boldsymbol X)^{-1}\\boldsymbol X^T\\boldsymbol y \\, .\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "meaning-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the MLE given X and y\n",
    "def max_lik_estimate(X, y):\n",
    "    # X: N x D matrix of training inputs\n",
    "    # y: N x 1 vector of training targets/observations\n",
    "    # returns: maximum likelihood parameters (D x 1)\n",
    "    N, D = X.shape\n",
    "    \n",
    "    beta_ml = np.linalg.solve(X.T @ X, X.T @ y)\n",
    "    return beta_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-start",
   "metadata": {},
   "source": [
    "Next we have a function that outputs the predicted values given some test data and the beta parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "understood-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_estimate(X_test, beta):\n",
    "    # X_test: K x D matrix of test inputs\n",
    "    # beta: D x 1 vector of parameters\n",
    "    # returns: prediction of f(X_test); K x 1 vector\n",
    "    \n",
    "    prediction = X_test @ beta\n",
    "    \n",
    "    return prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-fabric",
   "metadata": {},
   "source": [
    "The parameters of this particular model are obtained below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "earned-greene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.25206705e+01 -6.23509421e-01  5.07191271e+03 -3.55100636e+04\n",
      "  3.55098886e+04  1.39496495e+09  9.79427526e+02 -1.64223172e-01\n",
      "  1.20208274e+03 -9.76305983e+02 -5.01509709e-02 -6.12934767e+03\n",
      "  7.48646362e-01 -3.71494965e+00 -1.39496496e+09  6.12761154e+03\n",
      " -5.07077881e+03 -1.20558061e+03]\n"
     ]
    }
   ],
   "source": [
    "beta_ml = max_lik_estimate(X_train,Y_train)\n",
    "print(beta_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-bracelet",
   "metadata": {},
   "source": [
    "Next the in-sample MSE is calculated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "blessed-angola",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sample MSE    : 24.38006444485437\n"
     ]
    }
   ],
   "source": [
    "# in sample MSE\n",
    "train_preds = predict_with_estimate(X_train, beta_ml)\n",
    "MSE_train = np.mean((Y_train - train_preds) ** 2)\n",
    "print(\"In sample MSE    : \" + str(MSE_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-litigation",
   "metadata": {},
   "source": [
    "#### Question 1.1.2\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-fisher",
   "metadata": {},
   "source": [
    "We then use the model on the test data and obtain a prediction which is used to compute the out-of-sample MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lined-reply",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of sample MSE: 19.525828624573784\n"
     ]
    }
   ],
   "source": [
    "# out of sample MSE\n",
    "test_preds = predict_with_estimate(X_test, beta_ml)\n",
    "MSE_test = np.mean((Y_test - test_preds) ** 2)\n",
    "print(\"Out of sample MSE: \" + str(MSE_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-gamma",
   "metadata": {},
   "source": [
    "We observe the the out-of-sample MSE seems to be lower than the in-sample MSE.\n",
    "Initially we might think this is strange as the model was trained using in-sample data, but performs better on the out-of-sample data.\n",
    "\n",
    "However this can be explained by the fact that there could be outliers in the training set causing the MSE to be higher. Furthermore, as the training set is assumed to be one random sample from the available data, this could just be a case where the sample is not representative of the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-poster",
   "metadata": {},
   "source": [
    "### 1.2 Ridge Regression\n",
    "***\n",
    "\n",
    "#### Question 1.2.1\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-trauma",
   "metadata": {},
   "source": [
    "Next we implement a ridge regression model, which is similar to linear regression, however we add a penalty term  $\\lambda$.\n",
    "\n",
    "So in the least squares sense of linear regression, the loss function is:\n",
    "\n",
    "$$\n",
    "\\underset{\\boldsymbol\\beta}{\\text{min}} \\ \\text{L}_{\\text{ridge}} (\\boldsymbol\\beta) = \\underset{\\boldsymbol\\beta}{\\text{min}} \\| \\mathcal Y - \\mathcal X \\boldsymbol\\beta \\|^2 + \\lambda \\| \\boldsymbol\\beta \\|^2 \n",
    "$$\n",
    "\n",
    "and the beta parameters we obtain is given by the formula:\n",
    "\n",
    "$$\n",
    "\\boldsymbol\\beta^{*}_{\\text{ridge}} = (\\boldsymbol X^T\\boldsymbol X + \\lambda I)^{-1}\\boldsymbol X^T\\boldsymbol y \\, .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-invitation",
   "metadata": {},
   "source": [
    "First we have a function to compute and return the beta parameters for ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ideal-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_estimate(X, y, penalty):\n",
    "    # X: N x D matrix of training inputs\n",
    "    # y: N x 1 vector of training targets/observations\n",
    "    # returns: maximum likelihood parameters (D x 1)\n",
    "    \n",
    "    N, D = X.shape\n",
    "    I = np.identity(D)\n",
    "    beta_ridge = np.linalg.solve(X.T @ X + penalty * I, X.T @ y)\n",
    "    return beta_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-kinase",
   "metadata": {},
   "source": [
    "As our aim is to perform cross-validation, next we have a function to randomly split a given dataset into the given number of folds as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "pleased-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_split(data, num_folds):\n",
    "  fold_size = int(len(data) / num_folds)\n",
    "  data_perm = np.random.permutation(data)\n",
    "  folds = []\n",
    "  for k in range(num_folds):\n",
    "    folds.append(data_perm[k*fold_size:(k+1)*fold_size, :])\n",
    "\n",
    "  return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-alloy",
   "metadata": {},
   "source": [
    "Next we aggregate the X and Y data into one array, so they can be used for cross validation.\n",
    "And we generate the folds which are stored in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "seventh-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.hstack((X_train, Y_train[:, np.newaxis]))\n",
    "\n",
    "# Generate the folds\n",
    "folds = cross_val_split(train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-nebraska",
   "metadata": {},
   "source": [
    "In order to scan the optimal $\\lambda$ term, we create a vector of different possible lambdas from 0 to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "great-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vec = np.linspace(0, 100, num=1001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-region",
   "metadata": {},
   "source": [
    "Finally, we create a function that has one loop through the set of folds and another loop over the vector of lambdas, and applies ridge ression to every possible combination of these.\n",
    "\n",
    "The training and validation MSEs are also computed in the function and they are stored in dictionaries which are returned at the end of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "floral-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_evaluate_ridge(folds, lambda_vec):\n",
    "    # create dictionaries\n",
    "    train_MSE = {1:[], 2:[], 3:[], 4:[], 5:[]}\n",
    "    val_MSE = {1:[], 2:[], 3:[], 4:[], 5:[]}\n",
    "\n",
    "    for i in range(len(folds)):\n",
    "        print('Fold', i+1)\n",
    "        # define the training set (i.e. selecting all folds and deleting the one used for validation)\n",
    "        train_set = np.delete(np.asarray(folds).reshape(len(folds), folds[0].shape[0], folds[0].shape[1]), i, axis=0)\n",
    "        train_folds = train_set.reshape(len(train_set)*train_set[0].shape[0], train_set[0].shape[1])\n",
    "        X_train = train_folds[:,:-1]\n",
    "        y_train = train_folds[:, -1]\n",
    "        \n",
    "        # define the validation set\n",
    "        val_fold = folds[i]\n",
    "        X_val = val_fold[:,:-1]\n",
    "        y_val = val_fold[:, -1]\n",
    "    \n",
    "        # train the model and obtain the parameters for each lambda\n",
    "        for pen in lambda_vec:\n",
    "            \n",
    "            beta_ridge = ridge_estimate(X_train, y_train, penalty=pen)\n",
    "            \n",
    "            # evaluate\n",
    "            # training data MSE\n",
    "            train_preds_ridge = predict_with_estimate(X_train, beta_ridge)\n",
    "            MSE_train_ridge = np.mean((y_train - train_preds_ridge) ** 2)\n",
    "            \n",
    "            # validation data MSE\n",
    "            test_preds_ridge = predict_with_estimate(X_val, beta_ridge)\n",
    "            MSE_val_ridge = np.mean((y_val - test_preds_ridge) ** 2)\n",
    "            \n",
    "            # store these in the appropriate dictionaries\n",
    "            train_MSE[i+1].append(MSE_train_ridge)\n",
    "            val_MSE[i+1].append(MSE_val_ridge)\n",
    "    \n",
    "    print(\"Training finished.\")\n",
    "    return train_MSE, val_MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-character",
   "metadata": {},
   "source": [
    "We then call and run the function using our folds and lambda vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "spanish-assembly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "train_MSE, val_MSE = cross_val_evaluate_ridge(folds, lambda_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-summer",
   "metadata": {},
   "source": [
    "Next, we consider a particular fold, in this case fold 1.\n",
    "And we plot the MSE errors obtained against the different penalty terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "processed-class",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal λ for Fold 1 is 3.9000000000000004\n"
     ]
    }
   ],
   "source": [
    "plt.title(\"Plot of MSE errors for over different penalty terms for Ridge Regression [Fold 1]\")\n",
    "plt.plot(lambda_vec, train_MSE[1], label = \"Training Errors\")\n",
    "plt.plot(lambda_vec, val_MSE[1], label = \"Validation Errors\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"$\\lambda$\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()\n",
    "print(\"Optimal λ for Fold 1 is \" + str(lambda_vec[np.argmin(val_MSE[1])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-number",
   "metadata": {},
   "source": [
    "Note that the optimal $\\lambda$ for each fold is obtained by taking the index of the minimum of the validation MSE, and using that index to find the corresponding lambda.\n",
    "\n",
    "This is done for each of the five folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "controlled-confidentiality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal λ for Fold 1 is 3.9000000000000004\n",
      "Optimal λ for Fold 2 is 0.1\n",
      "Optimal λ for Fold 3 is 13.3\n",
      "Optimal λ for Fold 4 is 17.0\n",
      "Optimal λ for Fold 5 is 0.1\n"
     ]
    }
   ],
   "source": [
    "# The optimal lambdas for for each fold obtained using argmin\n",
    "for i in range(0,5):\n",
    "    print(\"Optimal λ for Fold \" + str(i+1) + \" is \" + str(lambda_vec[np.argmin(val_MSE[i+1])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-neighborhood",
   "metadata": {},
   "source": [
    "#### Question 1.2.2\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-transparency",
   "metadata": {},
   "source": [
    "In order to compute the average in-sample and out-of-sample MSEs, we first need to obtain the optimal $\\lambda$ out of all the folds.\n",
    "\n",
    "This is done by computing the average validation MSE over all the folds for each $\\lambda$, and then finding the minimum over this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hungry-bidding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal lambda is: 1.3\n"
     ]
    }
   ],
   "source": [
    "# Compute the average validation MSE over the folds, to get average for each penalty term\n",
    "average_val_MSE = np.mean([val_MSE[fold] for fold in range(1, 6)], axis = 0)\n",
    "optimal_lambda = lambda_vec[np.argmin(average_val_MSE)]\n",
    "print(\"The optimal lambda is: \" + str(optimal_lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-catering",
   "metadata": {},
   "source": [
    "We then train the model over the whole of the training data using this optimal lambda parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "australian-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_ridge = ridge_estimate(X_train, Y_train, penalty=optimal_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-argument",
   "metadata": {},
   "source": [
    "The resulting MSEs are obtained below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "mature-complexity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge - In sample error    : 24.559828320867624\n",
      "Ridge - Out of sample error: 19.360934376274972\n"
     ]
    }
   ],
   "source": [
    "# in sample MSE\n",
    "train_preds_ridge = predict_with_estimate(X_train, beta_ridge)\n",
    "MSE_train_ridge = np.mean((Y_train - train_preds_ridge) ** 2)\n",
    "\n",
    "# out of sample MSE\n",
    "test_preds_ridge = predict_with_estimate(X_test, beta_ridge)\n",
    "MSE_test_ridge = np.mean((Y_test - test_preds_ridge) ** 2)\n",
    "\n",
    "print(\"Ridge - In sample error    : \" + str(MSE_train_ridge))\n",
    "print(\"Ridge - Out of sample error: \" + str(MSE_test_ridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-tunnel",
   "metadata": {},
   "source": [
    "For comparsion, the MSEs obtained via linear regression are as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sporting-professional",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - In sample error    : 24.38006444485437\n",
      "Linear Regression - Out of sample error: 19.525828624573784\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression - In sample error    : \" + str(MSE_train))\n",
    "print(\"Linear Regression - Out of sample error: \" + str(MSE_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-hearing",
   "metadata": {},
   "source": [
    "Thus we can see that both the methods produce very similar results, with the ridge regression obtaining slightly out-of-sample MSE (which is the target we are interested in)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-retrieval",
   "metadata": {},
   "source": [
    "The ridge regression model has a penalty term whose effect is to try and keep the coefficients small, and the benefit of this is that there can be lower variance in the model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-appreciation",
   "metadata": {},
   "source": [
    "We do indeed observer that the the coefficients (the beta vector for ridge) are smaller:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "federal-provincial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear Regression Parameters</th>\n",
       "      <th>Ridge Regression Parameters</th>\n",
       "      <th>Absolute Difference in Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>β_0</th>\n",
       "      <td>22.521</td>\n",
       "      <td>22.455</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_1</th>\n",
       "      <td>-0.624</td>\n",
       "      <td>-0.636</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_2</th>\n",
       "      <td>5071.913</td>\n",
       "      <td>0.572</td>\n",
       "      <td>5071.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_3</th>\n",
       "      <td>-35510.064</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>35509.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_4</th>\n",
       "      <td>35509.889</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>35509.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_5</th>\n",
       "      <td>1394964953.358</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>1394964954.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_6</th>\n",
       "      <td>979.428</td>\n",
       "      <td>1.585</td>\n",
       "      <td>977.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_7</th>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_8</th>\n",
       "      <td>1202.083</td>\n",
       "      <td>-1.732</td>\n",
       "      <td>1203.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_9</th>\n",
       "      <td>-976.306</td>\n",
       "      <td>1.56</td>\n",
       "      <td>977.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_10</th>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_11</th>\n",
       "      <td>-6129.348</td>\n",
       "      <td>-0.872</td>\n",
       "      <td>6128.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_12</th>\n",
       "      <td>0.749</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_13</th>\n",
       "      <td>-3.715</td>\n",
       "      <td>-3.634</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_14</th>\n",
       "      <td>-1394964955.129</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>1394964954.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_15</th>\n",
       "      <td>6127.612</td>\n",
       "      <td>-0.872</td>\n",
       "      <td>6128.483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_16</th>\n",
       "      <td>-5070.779</td>\n",
       "      <td>0.572</td>\n",
       "      <td>5071.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β_17</th>\n",
       "      <td>-1205.581</td>\n",
       "      <td>-1.733</td>\n",
       "      <td>1203.847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Linear Regression Parameters  Ridge Regression Parameters  \\\n",
       "β_0                         22.521                       22.455   \n",
       "β_1                         -0.624                       -0.636   \n",
       "β_2                       5071.913                        0.572   \n",
       "β_3                     -35510.064                         -0.1   \n",
       "β_4                      35509.889                         -0.1   \n",
       "β_5                 1394964953.358                        -0.84   \n",
       "β_6                        979.428                        1.585   \n",
       "β_7                         -0.164                       -0.148   \n",
       "β_8                       1202.083                       -1.732   \n",
       "β_9                       -976.306                         1.56   \n",
       "β_10                         -0.05                       -0.092   \n",
       "β_11                     -6129.348                       -0.872   \n",
       "β_12                         0.749                         0.82   \n",
       "β_13                        -3.715                       -3.634   \n",
       "β_14               -1394964955.129                        -0.84   \n",
       "β_15                      6127.612                       -0.872   \n",
       "β_16                     -5070.779                        0.572   \n",
       "β_17                     -1205.581                       -1.733   \n",
       "\n",
       "      Absolute Difference in Parameters  \n",
       "β_0                               0.065  \n",
       "β_1                               0.012  \n",
       "β_2                             5071.34  \n",
       "β_3                           35509.963  \n",
       "β_4                           35509.988  \n",
       "β_5                      1394964954.198  \n",
       "β_6                             977.842  \n",
       "β_7                               0.017  \n",
       "β_8                            1203.814  \n",
       "β_9                             977.866  \n",
       "β_10                              0.042  \n",
       "β_11                           6128.475  \n",
       "β_12                              0.071  \n",
       "β_13                              0.081  \n",
       "β_14                     1394964954.289  \n",
       "β_15                           6128.483  \n",
       "β_16                           5071.351  \n",
       "β_17                           1203.847  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Differences observed in parameters\n",
    "abs_diff_beta = np.abs(beta_ml - beta_ridge)\n",
    "\n",
    "df_beta_parameters = pd.DataFrame(columns=['Linear Regression Parameters', \n",
    "                                           'Ridge Regression Parameters',\n",
    "                                           'Absolute Difference in Parameters'],\n",
    "                                  index=[['β_%s' %i for i in range(18)]],\n",
    "                                  data = np.array([beta_ml, beta_ridge, abs_diff_beta]).T)\n",
    "\n",
    "pd.set_option('display.float_format', str)\n",
    "\n",
    "df_beta_parameters.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-proposal",
   "metadata": {},
   "source": [
    "In particular, ridge regression is advantageous in the cases where many predictors are collinear with eachother, however if this is not the case then ridge may not provide any significant advantage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-digest",
   "metadata": {},
   "source": [
    "We can investigate this collinearity using a correlation matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "final-applicant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Correlation Matrix\n",
    "corr_mat = pd.DataFrame(X_train).corr()\n",
    "sns.heatmap(np.array(corr_mat)[1:, 1:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-township",
   "metadata": {},
   "source": [
    "Here, the lighter squares correspond to precitors being very correlated.\n",
    "We have excluded the column of ones here, and we observe that apart from the diagonal, there only seem to be very few highly correlated predictors. For example on the diagram we can observe predictors 1 and 15 appear to be highly correlated.\n",
    "\n",
    "However the vast majority are much darker, suggesting that there is not a significant amount of collinearity present in general. And hence ridge regression can only provide a small advantage (as seen by the lower MSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-receptor",
   "metadata": {},
   "source": [
    "### 1.3 Regression with $k$ nearest neighbours ($knn$)\n",
    "***\n",
    "\n",
    "#### Question 1.3.1\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-transformation",
   "metadata": {},
   "source": [
    "Firstly, we begin by making our knn algorithm.\n",
    "\n",
    "The k nearest neighbours algorithm works by computing the distances between a given test set and the samples from the training set. It then selects the $k$ nearest neighbours to each point in the test set, and in the case of regression, averages these values in the neighbourhood to form a prediciton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "western-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance function for kNN\n",
    "def euclidian_distance(p, q):\n",
    "    return np.sqrt(np.sum((q-p)**2, axis = 1))\n",
    "\n",
    "# function to find the k nearest neighbours in the training set given a test set\n",
    "def k_neighbours(X_train, X_test, k=5, return_distance=False):\n",
    "    dist = []\n",
    "    neigh_ind = []\n",
    "    \n",
    "    # compute distance from each point x_text in X_test to all points in X_train \n",
    "    point_dist =  [euclidian_distance(x_test, X_train) for x_test in X_test]\n",
    "    \n",
    "    # determine which k training points are closest to each test point\n",
    "    for row in point_dist:\n",
    "        enum_neigh = enumerate(row)\n",
    "        sorted_neigh = sorted(enum_neigh, key=lambda x: x[1])[:k]\n",
    "    \n",
    "        ind_list = [tup[0] for tup in sorted_neigh]\n",
    "        dist_list = [tup[1] for tup in sorted_neigh]\n",
    "    \n",
    "        dist.append(dist_list)\n",
    "        neigh_ind.append(ind_list)\n",
    "    \n",
    "    # return distances together with indices of k nearest neighbours\n",
    "    if return_distance:\n",
    "        return np.array(dist), np.array(neigh_ind)\n",
    "    \n",
    "    return np.array(neigh_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "indie-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to predict the values of the test points.\n",
    "def reg_predict(X_train, Y_train, X_test, k):\n",
    "    # each of the k neighbours contributes equally to the classification of any data point in X_test  \n",
    "    neighbours = k_neighbours(X_train, X_test, k=k)\n",
    "    # compute mean over neighbours labels \n",
    "    Y_pred = np.array([np.mean(Y_train[neighbour]) for neighbour in neighbours])\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-eligibility",
   "metadata": {},
   "source": [
    "Finally, we need a measure of how well the model predicts the y values.\n",
    "For this we use the $R^2$ score.\n",
    "\n",
    "$$\n",
    "R^2(y, \\hat{y}) = 1 - \\frac{\\sum_{i=1}^n (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2} \\, ,\n",
    "$$\n",
    "where $\\bar{y} = \\frac{1}{n} \\sum_{i=1}^n y_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dying-promotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that calculates the R2 score given the predictions and actual values\n",
    "def r2_score(y_test, y_pred):\n",
    "    numerator = np.sum((y_test - y_pred)**2)\n",
    "    y_avg = np.mean(y_test)\n",
    "    denominator = np.sum((y_test - y_avg)**2)\n",
    "    return 1 - numerator/denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-father",
   "metadata": {},
   "source": [
    "Again, in order to scan the optimal parameter term (in this case $k$), we create a vector of different possible values from 1 to 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "noticed-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vec = np.arange(50)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fifth-resident",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_evaluate_kNN(folds, k_vec):\n",
    "    \n",
    "    # create dictionaries\n",
    "    train_MSE = {1:[], 2:[], 3:[], 4:[], 5:[]}\n",
    "    val_MSE = {1:[], 2:[], 3:[], 4:[], 5:[]}\n",
    "\n",
    "    for i in range(len(folds)):\n",
    "      \n",
    "        print('Fold', i+1)\n",
    "        # define the training set (i.e. selecting all folds and deleting the one used for validation)\n",
    "        train_set = np.delete(np.asarray(folds).reshape(len(folds), folds[0].shape[0], folds[0].shape[1]), i, axis=0)\n",
    "        train_folds = train_set.reshape(len(train_set)*train_set[0].shape[0], train_set[0].shape[1])\n",
    "        X_train = train_folds[:,:-1]\n",
    "        y_train = train_folds[:, -1]\n",
    "        \n",
    "        # define the validation set\n",
    "        val_fold = folds[i]\n",
    "        X_val = val_fold[:,:-1]\n",
    "        y_val = val_fold[:, -1]\n",
    "    \n",
    "        # train the model and obtain the parameters for each k\n",
    "        for k_param in k_vec:                        \n",
    "            train_preds_kNN = reg_predict(X_train, y_train, X_train, k_param)\n",
    "            val_preds_kNN = reg_predict(X_train, y_train, X_val, k_param)\n",
    "            \n",
    "            # evaluate\n",
    "            # training data MSE\n",
    "            MSE_train_kNN = np.mean((y_train - train_preds_kNN) ** 2)\n",
    "            \n",
    "            # validation data MSE\n",
    "            MSE_val_kNN = np.mean((y_val - val_preds_kNN) ** 2)\n",
    "            \n",
    "            # store these in the appropriate dictionaries\n",
    "            train_MSE[i+1].append(MSE_train_kNN)\n",
    "            val_MSE[i+1].append(MSE_val_kNN)\n",
    "    \n",
    "   \n",
    "    print(\"Training finished.\")\n",
    "    return train_MSE, val_MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-reverse",
   "metadata": {},
   "source": [
    "As before, we create a function that has one loop through the set of folds and another loop over the vector of $k$s, and applies the kNN model for wach combination\n",
    "\n",
    "The training and validation MSEs are also computed similarly and stored in dictionaries again:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-excuse",
   "metadata": {},
   "source": [
    "Perform the cross validation for each parameter value as required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "foster-karma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "train_MSE_kNN, val_MSE_kNN = cross_val_evaluate_kNN(folds, k_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-machinery",
   "metadata": {},
   "source": [
    "Again, consider Fold 1 from our set of folds.\n",
    "We see in the function above that for this fold, a new model is created for each $k$, and the two MSEs are computed.\n",
    "These can then be plotted as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "sonic-hierarchy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Plot of MSE errors for over different k values for kNN [Fold 1]\")\n",
    "plt.plot(k_vec, train_MSE_kNN[1], label = \"Training Errors\")\n",
    "plt.plot(k_vec, val_MSE_kNN[1], label = \"Validation Errors\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-petroleum",
   "metadata": {},
   "source": [
    "From the plot we can see that the training MSE is a strictly increasing function of k, however for the validation error, there appears to be a minimum in the MSE between 0 and 10.\n",
    "\n",
    "We can obtain the optimal $k$ at which this happens using the \"argmin\" function as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "beneficial-gnome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal k for Fold 1 is 6\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal k for Fold 1 is \" + str(k_vec[np.argmin(val_MSE_kNN[1])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-lying",
   "metadata": {},
   "source": [
    "Similarly, the optimal parameter for each of the five folds are obtained below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "precious-competition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal k for Fold 1 is 6\n",
      "Optimal k for Fold 2 is 2\n",
      "Optimal k for Fold 3 is 5\n",
      "Optimal k for Fold 4 is 4\n",
      "Optimal k for Fold 5 is 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    print(\"Optimal k for Fold \" + str(i+1) + \" is \" + str(k_vec[np.argmin(val_MSE_kNN[i+1])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-homework",
   "metadata": {},
   "source": [
    "In terms of the distribution of errors, it makes sense that there will be an optimal $k$ corresponding to a local minimum of the validation MSE. \n",
    "\n",
    "For very small $k$, we expect the model to perform very well for the training set (as each prediction has the actual value as one of the few neighbours), however it is also likely overfit to this set, and as a result it will not be generalisable to any new set (such as the validation set)\n",
    "\n",
    "In contrast, if $k$ is very large, then the model will no longer be very local as many neighbours will be selected for each point. Thus, this will no longer perform well for either the training or the validation set.\n",
    "\n",
    "And thus we expect there to be a minimum value of k that is small, but not small enough to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-homeless",
   "metadata": {},
   "source": [
    "#### Question 1.3.1\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-punch",
   "metadata": {},
   "source": [
    "Next, we find the optimal value of k over all of the folds as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "canadian-attack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal k overall is: 2\n"
     ]
    }
   ],
   "source": [
    "# Compute the average validation MSE over the folds, to get average for each penalty term\n",
    "average_val_MSE_kNN = np.mean([val_MSE_kNN[fold] for fold in range(1, 6)], axis = 0)\n",
    "optimal_k = k_vec[np.argmin(average_val_MSE_kNN)]\n",
    "print(\"The optimal k overall is: \" + str(optimal_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-thesis",
   "metadata": {},
   "source": [
    "We then use this to train the model over the whole training dataset using the optimal $k$, and then obtain the in-sample and out-of-sample MSEs using the training and the test data respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "individual-richardson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-val kNN - In sample error        : 3.973725247524753\n",
      "Cross-val kNN - Out of sample error    : 13.935808823529408\n"
     ]
    }
   ],
   "source": [
    "# in sample MSE\n",
    "train_preds_kNN = reg_predict(X_train, Y_train, X_train, optimal_k)\n",
    "MSE_train_kNN = np.mean((Y_train - train_preds_kNN) ** 2)\n",
    "\n",
    "# out of sample MSE\n",
    "test_preds_kNN = reg_predict(X_train, Y_train, X_test, optimal_k)\n",
    "MSE_test_kNN = np.mean((Y_test - test_preds_kNN) ** 2)\n",
    "\n",
    "print(\"Cross-val kNN - In sample error        : \" + str(MSE_train_kNN))\n",
    "print(\"Cross-val kNN - Out of sample error    : \" + str(MSE_test_kNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-skirt",
   "metadata": {},
   "source": [
    "And we can also get a measure of the accuracies using the $R^2$ score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "close-demographic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-val kNN Train set mean accuracy  : 0.9557419532102102\n",
      "Cross-val kNN Test set mean accuracy   : 0.7619048240726203\n"
     ]
    }
   ],
   "source": [
    "print('Cross-val kNN Train set mean accuracy  :', r2_score(Y_train, train_preds_kNN))\n",
    "print('Cross-val kNN Test set mean accuracy   :', r2_score(Y_test, test_preds_kNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-tomorrow",
   "metadata": {},
   "source": [
    "The MSE values for each of the 3 models are summarised below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "crucial-arbor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>24.38006444485437</td>\n",
       "      <td>19.525828624573784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>24.559828320867624</td>\n",
       "      <td>19.360934376274972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kNN</th>\n",
       "      <td>3.973725247524753</td>\n",
       "      <td>13.935808823529408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Training         Validation\n",
       "Linear Regression  24.38006444485437 19.525828624573784\n",
       "Ridge Regression  24.559828320867624 19.360934376274972\n",
       "kNN                3.973725247524753 13.935808823529408"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_MSE = np.array([[MSE_train, MSE_test],[MSE_train_ridge, MSE_test_ridge], [MSE_train_kNN, MSE_test_kNN]])\n",
    "reg_MSE_df = pd.DataFrame(reg_MSE, columns = [\"Training\", \"Validation\"], index = [\"Linear Regression\", \"Ridge Regression\", \"kNN\"])\n",
    "reg_MSE_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-mexico",
   "metadata": {},
   "source": [
    "Thus we see that the kNN model appears to have a much higher performance when comparing the Validation MSEs.\n",
    "This could be explained by the fact that the Linear and Ridge regression models require the assumption of linearity in the data, however as kNN is a local model, it can also deal with any non-linearity which may be present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-haiti",
   "metadata": {},
   "source": [
    "Furthermore, as we have no other information about the data, we are unsure if the data is homogeneous or not (that is drawn from a single or similar populations).\n",
    "\n",
    "The fact that the regression models performed slighlty worse may suggest that there is some inhomogeneity iand so one regression model for all the data might not be suitable. One possible way we could deal with an inhomogeneous data set, is by fitting different models over different regions, for example various kNN models for particular regions, each with an optimal $k$ for that area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-jenny",
   "metadata": {},
   "source": [
    "## Task 2: Classification\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-eight",
   "metadata": {},
   "source": [
    "### 2.1 Logistic Regression\n",
    "***\n",
    "\n",
    "#### Question 2.1.1\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-gender",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
